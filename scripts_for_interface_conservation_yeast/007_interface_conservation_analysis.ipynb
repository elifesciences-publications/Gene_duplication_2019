{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interface conservation analyses\n",
    "\n",
    "This is the final script that will do the analyses of the sequence identity of paralogs at the interface. It will do the following steps:\n",
    "\n",
    "- 1.- Go through the list of best structures as to find the PDB structures I need (strict HMs and HETs)\n",
    "- 2.- Get the needed biological assembly for each of them. \n",
    "- 3.- Use such files to create dictionaries that remember which chains represent my paralogs of interest.\n",
    "- 4.- Identify the interfaces that include that chain. \n",
    "- 5.- Retrieve the sequence of each paralog pair and use the phylomeDB phylogenies to get alignments to calculate sequence identity at the interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import csv\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "from collections import OrderedDict\n",
    "import math\n",
    "from Bio.PDB import *\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import *\n",
    "from Bio.SeqRecord import *\n",
    "from Bio.Align.Applications import MuscleCommandline\n",
    "from shutil import copyfile\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define paths to input folders\n",
    "input_PDB = <path> # Folder with all the PDB files\n",
    "phylomeDB_path = <path> # Path to the alignments from PhylomeDB\n",
    "path_reference_proteome = <path> # Path to the reference proteome\n",
    "\n",
    "# Define paths to output_folders\n",
    "output_path = <path> # A parent folder for all the outputs\n",
    "output_004_bio_assemblies = <path> # Biological assemblies for each input PDB\n",
    "output_005_chain_match_tables = <path> # Chain match tables explaining which chains in the biological assembly come from which chain in the asymmetric unit\n",
    "output_006_dist_interfaces = <path> # Files with the calculated interfaces\n",
    "output_007_interface_dict = <path> # Files specifying which residues from each chain belong in interfaces\n",
    "output_008_phylo_PDB_seq = <path> # FASTA files containing PhylomeDB alignments, the paralogs, and the PDB sequence\n",
    "output_009_phylo_PDB_aln = <path> # FASTA files containing the aligned sequences from the output_008_phylo_seq folder\n",
    "output_010_only_PDB_positions = <path> # FASTA files containing the parts of the alignment that correspond to the region observed in the PDB structure\n",
    "output_011_only_interfaces = <path> # FASTA files containing the parts of the alignment that correspond to the interfaces observed in the PDB structure\n",
    "output_012_only_non_interfaces = <path> # FASTA files containing the parts of the alignment that correspond to the non-interfaces observed in the PDB structure\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add2dict(dictionary, key, value):\n",
    "    '''This is a small function I can use to add values to dictionaries. If the key is not\n",
    "    already in the dictionary, then it initializes its value as a list with one element (value).\n",
    "    Otherwise, it appends to that list.'''\n",
    "    \n",
    "    if dictionary.get(key, [-1]) == [-1]:\n",
    "        dictionary[key] = value\n",
    "    else:\n",
    "        curr_val = list(dictionary[key])\n",
    "        dictionary[key] = curr_val.append(value)\n",
    "    \n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.- Map each of the paralog pairs to their corresponding structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "handle_in = open('Data/paralogs_PDB_structures_best_structures.txt', 'r')\n",
    "reader = csv.reader(handle_in, delimiter = '\\t')\n",
    "\n",
    "paralogs2structures = OrderedDict()\n",
    "\n",
    "# Skip header\n",
    "header = reader.next()\n",
    "\n",
    "for line in reader:\n",
    "    P1 = line[0]\n",
    "    P2 = line[1]\n",
    "    HET = line[5]\n",
    "    P1_HM = line[8]\n",
    "    P2_HM = line[9]\n",
    "    \n",
    "    # Save the pair of paralogs as a key in the dictionary\n",
    "    paralogs2structures = add2dict(paralogs2structures, (P1, P2), OrderedDict())\n",
    "    \n",
    "    # Add each of the complexes only if it is not NA\n",
    "    if P1_HM != 'NA':\n",
    "        paralogs2structures[(P1, P2)] = add2dict(paralogs2structures[(P1, P2)], 'P1_HM', P1_HM)\n",
    "    if P2_HM != 'NA':\n",
    "        paralogs2structures[(P1, P2)] = add2dict(paralogs2structures[(P1, P2)], 'P2_HM', P2_HM)\n",
    "    if HET != 'NA':\n",
    "        paralogs2structures[(P1, P2)] = add2dict(paralogs2structures[(P1, P2)], 'HET', HET)\n",
    "\n",
    "handle_in.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.- Get the needed biological assemblies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use a loop to call the script that generates the biological assemblies\n",
    "for paralog_pair, struct_dict in paralogs2structures.items():\n",
    "    for key, structure in struct_dict.items():\n",
    "        assembly = structure[5:]\n",
    "        pdb = structure[0:4]\n",
    "        call_script = 'python ../scripts_for_simulations/001_generate_bio_assembly.py '\n",
    "        arg1 = '-i ' + input_PDB + '/' + pdb + '.pdb '\n",
    "        arg2 = '-o ' + output_004_bio_assemblies + '/' + structure + '.pdb '\n",
    "        arg3 = '-n ' + assembly + ' '\n",
    "        arg4 = '-t ' + output_005_chain_match_tables + '/' + pdb + '_chain_table.txt'\n",
    "        command = call_script + arg1 + arg2 + arg3 + arg4\n",
    "        os.system(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.- Use the matching tables and the previous alignments to know which chains correspond to my proteins of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the alignment data as a dictionary\n",
    "alignment_dict = OrderedDict()\n",
    "handle_in = open('Data/PDB_matches_all_chains_SSD_WGD.txt', 'r')\n",
    "reader = csv.reader(handle_in, delimiter = '\\t')\n",
    "\n",
    "unspecific_dict = OrderedDict()\n",
    "dup_type_dict = OrderedDict()\n",
    "\n",
    "for line in reader:\n",
    "    P1 = line[0]\n",
    "    P2 = line[14]\n",
    "    pair_list = [P1, P2]\n",
    "    pair_list.sort()\n",
    "    pair = tuple(pair_list)\n",
    "    \n",
    "    P1_match_PDB = line[1]\n",
    "    P1_match_chain = line[2]\n",
    "    \n",
    "    P1_unspecific = line[15]\n",
    "    P2_unspecific = line[16]\n",
    "    \n",
    "    dup_type = line[17]\n",
    "    \n",
    "    # Save the data about unspecific interactions and duplication types\n",
    "    unspecific_dict[P1] = P1_unspecific\n",
    "    unspecific_dict[P2] = P2_unspecific\n",
    "    \n",
    "    dup_type_dict[pair] = dup_type\n",
    "    \n",
    "    # Skip the first line\n",
    "    if P1 == 'P1':\n",
    "        continue\n",
    "    \n",
    "    # Start filling the dictionary\n",
    "    if alignment_dict.get(pair, -1) == -1:\n",
    "        # First level\n",
    "        alignment_dict[pair] = OrderedDict()\n",
    "        \n",
    "        # Second level\n",
    "        alignment_dict[pair][P1] = OrderedDict()\n",
    "        alignment_dict[pair][P2] = OrderedDict()\n",
    "        \n",
    "        # Third level\n",
    "        alignment_dict[pair][P1][P1_match_PDB] = [P1_match_chain]\n",
    "    \n",
    "    # When adding a new PDB structure\n",
    "    elif alignment_dict[pair][P1].get(P1_match_PDB, -1) == -1:\n",
    "        alignment_dict[pair][P1][P1_match_PDB] = [P1_match_chain]\n",
    "        \n",
    "    # When adding chains to a PDB structure\n",
    "    else:\n",
    "        alignment_dict[pair][P1][P1_match_PDB].append(P1_match_chain)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load all the data\n",
    "file_list = glob.glob(output_005_chain_match_tables + '/*')\n",
    "\n",
    "chain_dict = OrderedDict()\n",
    "for match_table in file_list:\n",
    "    structure = match_table.split('/')[-1][0:4]\n",
    "    handle = open(match_table, 'r')\n",
    "    reader = csv.reader(handle, delimiter = '\\t')\n",
    "    chain_dict[structure] = OrderedDict()\n",
    "    for line in reader:\n",
    "        key = line[0]\n",
    "        values = line[1].split(',')\n",
    "        chain_dict[structure][key] = values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.- Call the interfaces in each biological assembly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_pdb_line(pdb_line):\n",
    "    '''This function will receive a line from a PDB file and parse it as a list. It will do so based on the\n",
    "    PDB format explanation from this site:\n",
    "\n",
    "    https://www.cgl.ucsf.edu/chimera/docs/UsersGuide/tutorials/pdbintro.html\n",
    "    '''\n",
    "    atom = pdb_line[0:4].strip(' ')\n",
    "    atom_num = pdb_line[6:11].strip(' ')\n",
    "    atom_name = pdb_line[12:16].strip(' ')\n",
    "    resname = pdb_line[17:20].strip(' ')\n",
    "    chain = pdb_line[21]\n",
    "    res_num = pdb_line[22:26].strip(' ')\n",
    "    x = pdb_line[30:38].strip(' ')\n",
    "    y = pdb_line[38:46].strip(' ')\n",
    "    z = pdb_line[46:54].strip(' ')\n",
    "    region = float(pdb_line[61:66].strip())\n",
    "\n",
    "    return [atom, atom_num, atom_name, resname, chain, res_num, x, y, z, region]\n",
    "\n",
    "##################################\n",
    "\n",
    "def replace_b_factor(pdb_infile, in_dict, outfile):\n",
    "    '''This function uses an input PDB file, selects the lines that correspond to the atoms, and replaces their\n",
    "    b-factor values with the relative SASA from the dictionary. The output is written directly to a the outfile.'''\n",
    "    in_handle = open(pdb_infile, 'r')\n",
    "    out_handle = open(outfile, 'w')\n",
    "\n",
    "    for line in in_handle:\n",
    "        if line.startswith('ATOM'):\n",
    "\n",
    "            parsed_line = parse_pdb_line(line)\n",
    "\n",
    "            # Ignore DNA sequences\n",
    "            if parsed_line[3] in ['DA', 'DG', 'DC', 'DT', 'A', 'C', 'G', 'T', 'U']:\n",
    "                continue\n",
    "        \n",
    "            chain = parsed_line[4]\n",
    "            resid = parsed_line[5] + parsed_line[3]\n",
    "\n",
    "            dict_sasa = str(in_dict[chain].get(resid, 0.0)) +'0'\n",
    "            final_sasa = (6-len(dict_sasa))*' ' + dict_sasa\n",
    "\n",
    "            final_line = line.replace(line[60:66], final_sasa)\n",
    "            out_handle.write(final_line)\n",
    "\n",
    "    # Once the loop has finished, I can close the outfile\n",
    "    out_handle.close()\n",
    "\n",
    "##################################\n",
    "\n",
    "# Define a class for PDB coordinates\n",
    "class PDB_coordinates:\n",
    "    def __init__(self, x_coord, y_coord, z_coord, residue, atomtype):\n",
    "        '''The constructor for the PDB coordinates class'''\n",
    "        self.x = x_coord\n",
    "        self.y = y_coord\n",
    "        self.z = z_coord\n",
    "        self.residue = residue\n",
    "        self.atomtype = atomtype\n",
    "\n",
    "    def measure_distance(self, target):\n",
    "        '''A function I can use to measure the distance between two PDB_coordinates objects.'''\n",
    "        x_dist = (self.x - target.x)**2\n",
    "        y_dist = (self.y - target.y)**2\n",
    "        z_dist = (self.z - target.z)**2\n",
    "        return math.sqrt(x_dist + y_dist + z_dist)\n",
    "\n",
    "##################################\n",
    "\n",
    "def parse_coordinates(infile, alpha_only):\n",
    "    '''This function will parse a pdb file using the PDB_coordinates class.\n",
    "    If the \"alpha only\" argument is set to True the function will only look at \n",
    "    alpha carbons. It will look at all atoms if it is set to False.\n",
    "    '''\n",
    "    handle = open(infile, 'r')\n",
    "    coord_dict = OrderedDict()\n",
    "\n",
    "    for line in handle:\n",
    "        if line.startswith('ATOM'):\n",
    "\n",
    "            atom_line = parse_pdb_line(line)\n",
    "\n",
    "            # Ignore DNA sequences\n",
    "            if atom_line[3] in ['DA', 'DG', 'DC', 'DT', 'A', 'C', 'G', 'T', 'U']:\n",
    "                continue\n",
    "            \n",
    "            if alpha_only:\n",
    "\n",
    "                if atom_line[2] == 'CA':\n",
    "                    if coord_dict.get(atom_line[4], -1) == -1:\n",
    "                        coord_dict[atom_line[4]] = []\n",
    "                    # Add the atom to the list\n",
    "                    x_coord = float(atom_line[6])\n",
    "                    y_coord = float(atom_line[7])\n",
    "                    z_coord = float(atom_line[8])\n",
    "                    residue = atom_line[4] + atom_line[5] + atom_line[3]\n",
    "                    coord_dict[atom_line[4]].append(PDB_coordinates(x_coord, y_coord, z_coord, residue, 'CA'))\n",
    "            else:\n",
    "                if coord_dict.get(atom_line[4], -1) == -1:\n",
    "                        coord_dict[atom_line[4]] = []\n",
    "                # Add the atom to the list\n",
    "                x_coord = float(atom_line[6])\n",
    "                y_coord = float(atom_line[7])\n",
    "                z_coord = float(atom_line[8])\n",
    "                atomtype = atom_line[2]\n",
    "                residue = atom_line[4] + atom_line[5] + atom_line[3]\n",
    "                coord_dict[atom_line[4]].append(PDB_coordinates(x_coord, y_coord, z_coord, residue, atomtype))\n",
    "\n",
    "    return coord_dict\n",
    "\n",
    "##################################\n",
    "\n",
    "def get_vdw_dict(infile):\n",
    "    '''This function parses the FreeSasa file I will use as a reference for the van der Waals radii.\n",
    "    '''\n",
    "    handle = open(infile, 'r')\n",
    "\n",
    "    vdw_dict = {}\n",
    "\n",
    "    for line in handle:\n",
    "        if line.startswith('ATOM'):\n",
    "            line_list = re.split('\\s+', line)\n",
    "\n",
    "            aminoacid = line_list[3]\n",
    "            atomtype = line_list[2]\n",
    "            vdw_radius = float(line_list[9])\n",
    "            # Add the amino acid if it has not been registered\n",
    "            if vdw_dict.get(aminoacid, -1) == -1:\n",
    "                vdw_dict[aminoacid] = {'OXT' : 1.46}\n",
    "            # Add the vdw radius for the current atomtype for this aminoacid if it has not been registered\n",
    "            if vdw_dict[aminoacid].get(atomtype, -1) == -1:\n",
    "                vdw_dict[aminoacid][atomtype] = vdw_radius\n",
    "\n",
    "    # Now that I finished, I can return the dictionary\n",
    "    return vdw_dict\n",
    "\n",
    "ref_vdw_dict = '../scripts_for_simulations/Data/1aof_sasa.pdb'\n",
    "vdw_dict = get_vdw_dict(ref_vdw_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the main function that will find interfaces\n",
    "def distance_interfaces(pdb_file, out_pdb_dist):\n",
    "    alpha_carbons = parse_coordinates(pdb_file, True)\n",
    "    chains = alpha_carbons.keys()\n",
    "\n",
    "    distance_region_dict = OrderedDict()\n",
    "    for chain in chains:\n",
    "        distance_region_dict[chain] = OrderedDict()\n",
    "\n",
    "    all_atoms = parse_coordinates(pdb_file, False)\n",
    "\n",
    "    alpha_carbon_residue_list = []\n",
    "    \n",
    "    for chainA_num in range(len(chains) - 1):\n",
    "        chainA = chains[chainA_num]\n",
    "\n",
    "        for chainB_num in range(chainA_num + 1, len(chains)):\n",
    "            chainB = chains[chainB_num]\n",
    "            \n",
    "            # I will compare the distances for the alpha carbons\n",
    "            for alphaA in alpha_carbons[chainA]:\n",
    "                residueA = alphaA.residue[1:]\n",
    "            \n",
    "                for alphaB in alpha_carbons[chainB]:\n",
    "\n",
    "                    residueB = alphaB.residue[1:]\n",
    "\n",
    "                    # Use this code to distinguish regions\n",
    "                    # 0.00 = neither nearby nor interacting\n",
    "                    # 0.25 = interaction candidates (used to reduce the number of all-atom measurements)\n",
    "                    # 0.75 = nearby\n",
    "                    # 1.00 = interacting\n",
    "                    if distance_region_dict[chainA].get(residueA, -1) != 0.25:\n",
    "                        distance_region_dict[chainA][residueA] = 0.00\n",
    "\n",
    "                    if distance_region_dict[chainB].get(residueB, -1) != 0.25:\n",
    "                        distance_region_dict[chainB][residueB] = 0.00\n",
    "\n",
    "                    # Get candidates based on their alpha carbons\n",
    "                    if alphaA.measure_distance(alphaB) <= 10:\n",
    "\n",
    "                        distance_region_dict[chainA][residueA] = 0.25\n",
    "                        distance_region_dict[chainB][residueB] = 0.25\n",
    "\n",
    "    # Save a dictionary of the residues that make up each interface\n",
    "    interacting_dict = OrderedDict()\n",
    "    for chainA_num in range(len(chains) - 1):\n",
    "        chainA = chains[chainA_num]\n",
    "        for chainB_num in range(chainA_num + 1, len(chains)):\n",
    "            chainB = chains[chainB_num]\n",
    "            interacting_dict[(chainA, chainB)] = [[], []]            \n",
    "    \n",
    "    # Look at all the atom pairwise comparisons between interacting candidates\n",
    "    for chainA_num in range(len(chains) - 1):\n",
    "        chainA = chains[chainA_num]\n",
    "        for atomA in all_atoms[chainA]:\n",
    "            residueA = atomA.residue[1:] \n",
    "            # Only keep going if this is a candidate\n",
    "            if distance_region_dict[chainA].get(residueA, 0) >= 0.25:\n",
    "                for chainB_num in range(chainA_num + 1, len(chains)):           \n",
    "                    chainB = chains[chainB_num]\n",
    "                    for atomB in all_atoms[chainB]:\n",
    "                        residueB = atomB.residue[1:]\n",
    "                        # Only keep going if this is a candidate\n",
    "                        if distance_region_dict[chainB].get(residueB, 0) >= 0.25:\n",
    "\n",
    "                            vdw_atomA = vdw_dict[residueA[-3:]][atomA.atomtype]\n",
    "                            vdw_atomB = vdw_dict[residueB[-3:]][atomB.atomtype]\n",
    "                            atom_distance = atomA.measure_distance(atomB)\n",
    "\n",
    "                            # Check if the atoms are interacting\n",
    "                            if atom_distance < vdw_atomA + vdw_atomB + 0.5:\n",
    "                                # I can list them as interacting residues\n",
    "                                distance_region_dict[chainA][residueA] = 1.00\n",
    "                                distance_region_dict[chainB][residueB] = 1.00\n",
    "\n",
    "                                # I can save them to the dictionary\n",
    "                                if not residueA in interacting_dict[(chainA, chainB)][0]:\n",
    "                                    interacting_dict[(chainA, chainB)][0].append(residueA)\n",
    "                                if not residueB in interacting_dict[(chainA, chainB)][1]:\n",
    "                                    interacting_dict[(chainA, chainB)][1].append(residueB)\n",
    "\n",
    "    # Use the interacting residues to find the nearby residues\n",
    "    all_alpha = []\n",
    "    for chain in chains:\n",
    "        all_alpha = all_alpha + alpha_carbons[chain]\n",
    "    \n",
    "    # Keep track of comparisons to avoid repeating\n",
    "    for pos1 in range(0,len(all_alpha)-1):\n",
    "\n",
    "        alpha1 = all_alpha[pos1]\n",
    "        residue1 = alpha1.residue[1:]\n",
    "        chain1 = alpha1.residue[0]\n",
    "\n",
    "        for pos2 in range(pos1+1, len(all_alpha)):\n",
    "            alpha2 = all_alpha[pos2]\n",
    "            residue2 = alpha2.residue[1:]\n",
    "            chain2 = alpha2.residue[0]\n",
    "\n",
    "            if alpha1.measure_distance(alpha2) <= 6:\n",
    "\n",
    "                # If residueB is near an interacting residue, classify it as nearby\n",
    "                if distance_region_dict[chain1][residue1] == 1.00 and distance_region_dict[chain2][residue2] < 0.75:\n",
    "                    distance_region_dict[chain2][residue2] = 0.75\n",
    "                    # Add the nearby residue to the interface dict\n",
    "                    for chain_pair, interface_lists in interacting_dict.items():\n",
    "                        if residue1 in interface_lists[0] and chain2 == chain_pair[0]:\n",
    "                            interacting_dict[chain_pair][0].append(residue2)\n",
    "                        if residue1 in interface_lists[1] and chain2 == chain_pair[1]:\n",
    "                            interacting_dict[chain_pair][1].append(residue2)\n",
    "\n",
    "                # If residueA is near an interacting residue, classify it as nearby\n",
    "                if distance_region_dict[chain2][residue2] == 1.00 and distance_region_dict[chain1][residue1] < 0.75:\n",
    "                    distance_region_dict[chain1][residue1] = 0.75\n",
    "                    # Add the nearby residue to the interface dict\n",
    "                    for chain_pair, interface_lists in interacting_dict.items():\n",
    "                        if residue2 in interface_lists[0] and chain1 == chain_pair[0]:\n",
    "                            interacting_dict[chain_pair][0].append(residue1)\n",
    "                        if residue2 in interface_lists[1] and chain1 == chain_pair[1]:\n",
    "                            interacting_dict[chain_pair][1].append(residue1)\n",
    "    \n",
    "    # Set interaction candidates that do not interact to non interfaces\n",
    "    for chain in chains:\n",
    "        for alpha_carbon in alpha_carbons[chain]:\n",
    "            residue = alpha_carbon.residue[1:]\n",
    "            chain = alpha_carbon.residue[0]\n",
    "            if distance_region_dict[chain][residue] == 0.25:\n",
    "                distance_region_dict[chain][residue] = 0.00\n",
    "\n",
    "    # Write the new PDB file with the regions\n",
    "    replace_b_factor(pdb_file, distance_region_dict, out_pdb_dist)\n",
    "    \n",
    "    return(interacting_dict)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The main block that calculates interfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the list of files\n",
    "file_list = glob.glob(output_004_bio_assemblies + '/*')\n",
    "\n",
    "# Call interfaces\n",
    "for pdb_file in file_list:\n",
    "    print pdb_file\n",
    "    structure = pdb_file.split('/')[-1][0:4]\n",
    "    out_file = output_006_dist_interfaces + '/dist_regions_' + structure + '.pdb'\n",
    "    interacting_dict = distance_interfaces(pdb_file, out_file)\n",
    "    \n",
    "    # Save the interacting dict to a file\n",
    "    int_dict_file = open(output_007_interface_dict + '/' + structure + '_interface_dict.txt', 'w')\n",
    "    writer = csv.writer(int_dict_file, delimiter = '\\t')\n",
    "    for key, value in interacting_dict.items():\n",
    "        col1 = ','.join(key)\n",
    "        col2_1 = ','.join(value[0])\n",
    "        col2_2 = ','.join(value[1])\n",
    "        col2 = col2_1 + ';' + col2_2\n",
    "        writer.writerow([col1, col2])\n",
    "    int_dict_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.- Retrieve the interfaces and start looking at their conservation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For all pairs of paralogs, the table that helps me match the pairs\n",
    "integrated_table_file = 'Data/paralogs_PDB_structures_best_structures.txt'\n",
    "\n",
    "P1_id = 'YDL022W'\n",
    "\n",
    "phylomedb_path = phylomeDB_path\n",
    "desired_regions = [0.75, 1.00]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load a dictionary that helps me map the protein IDs to PhylomeDB IDs\n",
    "handle = open(\"Data/yeast_SN_genes_names.txt\", 'r')\n",
    "reader = csv.reader(handle, delimiter = '\\t')\n",
    "\n",
    "systematic2phylomeDB = OrderedDict()\n",
    "phylomeDB2systematic = OrderedDict()\n",
    "for line in reader:\n",
    "    systematic2phylomeDB[line[1]] = line[0]\n",
    "    phylomeDB2systematic[line[0]] = line[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define some functions\n",
    "def align_seqs(in_fasta):\n",
    "    '''This function will take the FASTA file with the PDB entry's sequences and\n",
    "    align them. It will return a dictionary with the aligned sequences.\n",
    "    '''\n",
    "    muscle_cline = MuscleCommandline(input = in_fasta)\n",
    "\n",
    "    stdout, stderr = muscle_cline()\n",
    "    \n",
    "    align_dict = {}\n",
    "    for line in stdout.split('\\n'):\n",
    "        if line.startswith('>'):\n",
    "            \n",
    "            current_chain = line.split(' ')[0]\n",
    "            \n",
    "            if current_chain[1:] in align_dict.keys():\n",
    "                current_chain = current_chain + '2'\n",
    "            align_dict[current_chain[1:]] = ''\n",
    "        else:\n",
    "            align_dict[current_chain[1:]] = align_dict[current_chain[1:]] + line\n",
    "        \n",
    "    return align_dict\n",
    "\n",
    "#########################################\n",
    "\n",
    "def align2records(alignment):\n",
    "    '''This function will receive a muscle alignment and change it into a list of records that can be saved.\n",
    "    '''\n",
    "    records = []\n",
    "    for prot_id, sequence in alignment.items():\n",
    "        new_record = SeqRecord(seq = Seq(sequence), id = prot_id, description = '')\n",
    "        records.append(new_record)\n",
    "    return records\n",
    "\n",
    "#########################################\n",
    "\n",
    "def percentage_identity(in_file):\n",
    "    '''This function will receive a fasta file with two sequences and calculate their sequence identity.\n",
    "    '''\n",
    "    records = []\n",
    "    for record in SeqIO.parse(in_file, 'fasta'):\n",
    "        records.append(record)\n",
    "    \n",
    "    total_residues = len(record.seq)\n",
    "    if total_residues == 0:\n",
    "        return 0\n",
    "    \n",
    "    matches = 0.0\n",
    "    dual_gaps = 0.0\n",
    "    seq1 = records[0]\n",
    "    seq2 = records[1]\n",
    "    for pos in range(total_residues):\n",
    "        if seq1[pos] == seq2[pos]:\n",
    "            if seq1[pos] == '-':\n",
    "                dual_gaps += 1.0\n",
    "            else:\n",
    "                matches = matches + 1.0\n",
    "        \n",
    "    return round(matches*100/(total_residues - dual_gaps), 2)\n",
    "\n",
    "#########################################\n",
    "\n",
    "def percentage_identity2(align_dict):\n",
    "    '''This function will receive a dictionary with two sequences and calculate their sequence identity.\n",
    "    '''\n",
    "    seq1 = align_dict.values()[0]\n",
    "    seq2 = align_dict.values()[1]\n",
    "    \n",
    "    total_residues = len(seq1)\n",
    "    matches = 0.0\n",
    "    dual_gaps = 0.0\n",
    "    for pos in range(total_residues):\n",
    "        if seq1[pos] == seq2[pos]:\n",
    "            if seq1[pos] == '-':\n",
    "                dual_gaps += 1.0\n",
    "            else:\n",
    "                matches = matches + 1.0\n",
    "        \n",
    "    return round(matches*100/(total_residues - dual_gaps), 2)\n",
    "\n",
    "#########################################\n",
    "\n",
    "def region_parser(interface_file, aa_dict):\n",
    "    '''This function takes a PDB file in which regions have been called in order to identify the interfaces.\n",
    "    It returns a dictionary in which residues map to a two-element list:\n",
    "    - First position: True if they belong to the desired regions and False otherwise\n",
    "    - Second position: The ID of the region to which they belong\n",
    "    '''\n",
    "    \n",
    "    interface_file_handle = open(interface_file, 'r')\n",
    "\n",
    "    # Create a dictionary that will store the chains, its residues, and the regions to which they belong\n",
    "    pdb_dict = OrderedDict()\n",
    "    start_dict = OrderedDict()\n",
    "    end_dict = OrderedDict()\n",
    "    \n",
    "    sequence_dict = OrderedDict()\n",
    "\n",
    "    # Save the previous position number to make sure I deal with alternative coordinates\n",
    "    prev_pos = 'X'\n",
    "    \n",
    "    # Parse the file into the dictionary\n",
    "    for line in interface_file_handle:\n",
    "        pdb_line = parse_pdb_line(line)\n",
    "\n",
    "        # Add the data for this residue to the dictionary\n",
    "        res_id = pdb_line[3] + pdb_line[5]\n",
    "        region = pdb_line[9]\n",
    "        chain = pdb_line[4]\n",
    "        atom_type = pdb_line[2]\n",
    "        \n",
    "        # Keep track of the start and the end positions\n",
    "        curr_pos = int(pdb_line[5])\n",
    "\n",
    "        # Look at alpha carbons to avoid repeating\n",
    "        if atom_type == 'CA' and prev_pos != curr_pos:\n",
    "\n",
    "            prev_pos = curr_pos\n",
    "            \n",
    "            # Keep track of the start and end positions\n",
    "            if not chain in start_dict.keys():\n",
    "                start_dict[chain] = curr_pos\n",
    "            elif start_dict[chain] > curr_pos:\n",
    "                start_dict[chain] = curr_pos\n",
    "\n",
    "            if not chain in end_dict.keys():\n",
    "                end_dict[chain] = curr_pos\n",
    "            elif end_dict[chain] < curr_pos:\n",
    "                end_dict[chain] = curr_pos\n",
    "\n",
    "            # Save the regions to which each residue belongs\n",
    "            if pdb_dict.get(chain, -1) == -1:\n",
    "                pdb_dict[chain] = OrderedDict()\n",
    "                pdb_dict[chain][res_id] = region\n",
    "            else:\n",
    "                pdb_dict[chain][res_id] = region\n",
    "\n",
    "            # Save sequences\n",
    "            if sequence_dict.get(chain, -1) == -1:\n",
    "                sequence_dict[chain] = aa_dict[res_id[0:3]]\n",
    "            else:\n",
    "                sequence_dict[chain] += aa_dict[res_id[0:3]]\n",
    "\n",
    "            \n",
    "    return pdb_dict, start_dict, end_dict, sequence_dict\n",
    "\n",
    "#########################################\n",
    "\n",
    "def extract_PDB_region(alignment_dict, P1_id, output_path):\n",
    "    ''' This function will receive the alignment parsed as a dictionary and return the region of the alignment\n",
    "    that corresponds to residues in the PDB sequence. It will write the resulting sequences to a file in\n",
    "    the 010_only_PDB_positions folder in the output path.\n",
    "    '''\n",
    "    # Using the MSA, extract the part of the sequences that match to the PDB.\n",
    "    start = -1\n",
    "    end = -1\n",
    "    PDB_seq = alignment_dict[P1_id + \"_pdb\"].seq\n",
    "    for pos in range(0,len(PDB_seq)):\n",
    "        if PDB_seq[pos] != '-':\n",
    "            # Assign this position to the end because it contains an amino acid\n",
    "            end = pos\n",
    "            # If this is the first one, save it as the start\n",
    "            if start == -1:\n",
    "                start = pos\n",
    "\n",
    "    ### Knowing the start and end positions, save these sequences in the 007 folder.\n",
    "    only_PDB_positions = []\n",
    "    for key, record in alignment_dict.items():\n",
    "        # Only save the records that are not the PDB sequence\n",
    "        if key != P1_id + \"_pdb\":\n",
    "            new_record = SeqRecord(record.seq[start:end], id = key, description = '')\n",
    "            only_PDB_positions.append(new_record)\n",
    "\n",
    "    SeqIO.write(only_PDB_positions, os.path.join(output_path, P1_id + \"_only_PDB_pos.fasta\"), \"fasta\")\n",
    "    return(PDB_seq)\n",
    "\n",
    "#########################################\n",
    "\n",
    "def fasta2list(in_fasta):\n",
    "    ''' This function receives a multi fasta file and saves its records to a list.\n",
    "    '''\n",
    "    phylo_records = []\n",
    "    for record in SeqIO.parse(in_fasta, \"fasta\"):\n",
    "        phylo_records.append(record)\n",
    "    return phylo_records\n",
    "\n",
    "########################################\n",
    "\n",
    "def fasta2dict(in_fasta):\n",
    "    '''This function receives a multi fasta file and parses it into a dictionary.\n",
    "    '''\n",
    "    dict_out = OrderedDict()\n",
    "    for record in SeqIO.parse(in_fasta, \"fasta\"):\n",
    "        dict_out[record.id] = record\n",
    "    return dict_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add MSE (selenomethionine) as M and MLY (methylysine) as K\n",
    "aa_dict = {\n",
    "    'ALA':'A',\n",
    "    'ARG':'R',\n",
    "    'ASN': 'N',\n",
    "    'ASP': 'D',\n",
    "    'CYS':'C',\n",
    "    'GLU':'E',\n",
    "    'GLN':'Q',\n",
    "    'GLY':'G',\n",
    "    'HIS':'H',\n",
    "    'ILE':'I',\n",
    "    'LEU':'L',\n",
    "    'LYS':'K',\n",
    "    'MET':'M',\n",
    "    'PHE':'F',\n",
    "    'PRO':'P',\n",
    "    'SER':'S',\n",
    "    'THR':'T',\n",
    "    'TRP':'W',\n",
    "    'TYR':'Y',\n",
    "    'VAL':'V',\n",
    "    'MSE':'M',\n",
    "    'MLY':'K'\n",
    "}\n",
    "\n",
    "aa2three_letter = OrderedDict()\n",
    "for key, value in aa_dict.items():\n",
    "    if key in ('MSE', 'MLY'):\n",
    "        continue\n",
    "    else:\n",
    "        aa2three_letter[value] = key\n",
    "\n",
    "desired_regions = [0.75, 1.00]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the yeast reference proteome so that I can extract sequences easily\n",
    "# Needed whenever the sequences are missing from the PhylomeDB alignments\n",
    "proteome_dict = OrderedDict()\n",
    "pdb_seqs = SeqIO.parse(path_reference_proteome, 'fasta')\n",
    "for record in pdb_seqs:\n",
    "    proteome_dict[record.id] = record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I will define the functions to work with the PDB sequences here\n",
    "def match_PDB_full_seq(align_dict, PDB_dict, full_seq_id, pdb_seq_id, aa2three_letter):\n",
    "    '''This function will help me find assign PDB regions for the full sequence.\n",
    "    '''\n",
    "    # Retrieve the aligned sequences\n",
    "    aligned_chain_pdb = align_dict[pdb_seq_id]\n",
    "    aligned_chain_full = align_dict[full_seq_id]\n",
    "    \n",
    "    counter_pdb = 0\n",
    "    counter_full = 0\n",
    "    \n",
    "    # Loop through the keys of the dictionary\n",
    "    pdb_residues = PDB_dict.keys()\n",
    "    \n",
    "    match_list = []\n",
    "    full_region_dict = OrderedDict()\n",
    "    \n",
    "    # Loop through the positions of the PDB chain\n",
    "    for position in range(len(aligned_chain_pdb)):\n",
    "        # Get the residue in this position \n",
    "        aligned_pdb = aligned_chain_pdb[position]\n",
    "        \n",
    "        if counter_pdb < len(pdb_residues):\n",
    "            pdb_pos = pdb_residues[counter_pdb]\n",
    "        else:\n",
    "            pdb_pos = '---'\n",
    "        \n",
    "        # Get the residue in this position for the full sequence\n",
    "        aligned_full = aligned_chain_full[position]\n",
    "    \n",
    "        # Look at the four possible scenarios with respect to gaps in the sequences\n",
    "        if aligned_pdb == '-' and aligned_full == '-':\n",
    "            continue\n",
    "        elif aligned_pdb == '-' and aligned_full != '-':\n",
    "            # This is a gap in the PDB sequence.\n",
    "            full_pos = aa2three_letter[aligned_full] + str(counter_full)\n",
    "            full_region_dict[full_pos] = -1\n",
    "            match_list.append(['-', full_pos, -1])\n",
    "            counter_full = counter_full + 1\n",
    "        elif aligned_pdb != '-' and aligned_full == '-':\n",
    "            # This is a gap in the full sequence.\n",
    "            counter_pdb = counter_pdb + 1\n",
    "        elif aligned_pdb != '-' and aligned_full != '-':\n",
    "            # Make sure that the alignment position residue type matches the query\n",
    "            if aa2three_letter.get(aligned_pdb, -1) != pdb_pos[0:3]:\n",
    "                # This will identify unusual residues\n",
    "                print 'Found something else', pdb_pos, aligned_pdb, structure\n",
    "            else:\n",
    "                region = PDB_dict.get(pdb_pos, '-')\n",
    "                # Save a dictionary with the matches\n",
    "                full_pos = aa2three_letter[aligned_full] + str(counter_full)\n",
    "                match_list.append([pdb_pos, full_pos, region])\n",
    "\n",
    "                # Add one to the PDB counter and to the full counter\n",
    "                counter_pdb = counter_pdb + 1\n",
    "                counter_full = counter_full + 1\n",
    "\n",
    "                full_region_dict[full_pos] = region\n",
    "\n",
    "        #####################################\n",
    "    \n",
    "    # Return the dictionary that maps each residue in the sequence to the available structural information\n",
    "    return full_region_dict, match_list\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the PhylomeDB phylogenies to get sequence identities at the interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def first_round_alignments2(phylo_dict, phylo_ID, paralog_ID, alignment_dict, chain_dict):\n",
    "    '''This function takes the dictionaries and does the first alignment, that is, the sequence from the PDB to\n",
    "    the full protein, which will help identify the position of the interfaces in that full protein.\n",
    "    '''\n",
    "    needed_chains = alignment_dict[(P1, P2)][paralog_ID][structure[0:4]]\n",
    "    for needed_chain in needed_chains:\n",
    "        new_chain = chain_dict[structure[0:4]][needed_chain][0]\n",
    "        if new_chain != '':\n",
    "            break\n",
    "    pdb_sequence = pdb_sequence_dict[new_chain]\n",
    "    \n",
    "    # The pdb_dict already has all residues that belong to the interface of at least one of the subunits\n",
    "    PDB_sequence_record = SeqRecord(Seq(pdb_sequence), id = paralog_ID + '_pdb', description = '')\n",
    "\n",
    "    # Make records with these two sequences and align them\n",
    "    full_seq_record = phylo_dict[phylo_ID]\n",
    "    records = [full_seq_record, PDB_sequence_record]\n",
    "\n",
    "    pdb_seq_id = PDB_sequence_record.id\n",
    "    full_seq_id = full_seq_record.id\n",
    "\n",
    "    # Write the PDB sequence and the full sequence for that protein\n",
    "    outpath = output_008_phylo_PDB_seq + '/' + phylo_ID + '.fasta'\n",
    "    SeqIO.write(records, outpath, 'fasta')\n",
    "\n",
    "    # Align with MUSCLE\n",
    "    aln_dict = align_seqs(outpath)\n",
    "    \n",
    "    # Use the alignment dict to know where the PDB chain matches the full sequence \n",
    "    full_region_dict, match_list = match_PDB_full_seq(aln_dict, pdb_dict[new_chain], full_seq_id, pdb_seq_id, aa2three_letter)\n",
    "    \n",
    "    return full_region_dict, match_list\n",
    "    \n",
    "    ####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_final_sequences2(phylo_dict, full_region_dict, phylo_ID_2, phylo_ID, aa2three_letter):\n",
    "    '''This function transfers the annotation to the second paralog and writes the final files.'''\n",
    "\n",
    "    full_region_dict_2, match_list_2 = match_PDB_full_seq(phylo_dict, full_region_dict, phylo_ID_2, phylo_ID, aa2three_letter)\n",
    "    \n",
    "    pdb_seqs = ['','']\n",
    "    only_interfaces = ['','']\n",
    "    only_non_interfaces = ['','']\n",
    "    for position in match_list_2: \n",
    "        if position[2] >= 0.00:  \n",
    "            # Add to the pdb sequences\n",
    "            pdb_seqs[0] = pdb_seqs[0] + aa_dict[position[0][0:3]]\n",
    "            pdb_seqs[1] = pdb_seqs[1] + aa_dict[position[1][0:3]]\n",
    "\n",
    "            # Check region to decide where to add it\n",
    "            if position[2] >= 0.75:\n",
    "                # Add to interfaces\n",
    "                only_interfaces[0] = only_interfaces[0] + aa_dict[position[0][0:3]]\n",
    "                only_interfaces[1] = only_interfaces[1] + aa_dict[position[1][0:3]]\n",
    "            else:\n",
    "                only_non_interfaces[0] = only_non_interfaces[0] + aa_dict[position[0][0:3]]\n",
    "                only_non_interfaces[1] = only_non_interfaces[1] + aa_dict[position[1][0:3]]\n",
    "\n",
    "    # Save these sequences as records and write them\n",
    "    # PDB seqs\n",
    "    record_1 = SeqRecord(seq = Seq(pdb_seqs[0]), id = paralog_ID)\n",
    "    record_2 = SeqRecord(seq = Seq(pdb_seqs[1]), id = paralog_ID_2)\n",
    "    records = [record_1, record_2]\n",
    "    out_pdb = output_010_only_PDB_positions + '/' + P1 + '_' + P2 + '_only_pdb_positions.fasta'\n",
    "    SeqIO.write(records, out_pdb, 'fasta')\n",
    "\n",
    "    # Only interfaces\n",
    "    record_1 = SeqRecord(seq = Seq(only_interfaces[0]), id = paralog_ID)\n",
    "    record_2 = SeqRecord(seq = Seq(only_interfaces[1]), id = paralog_ID_2)\n",
    "    records = [record_1, record_2]\n",
    "    out_interfaces = output_011_only_interfaces + '/' + P1 + '_' + P2 + '_only_interfaces.fasta'\n",
    "    SeqIO.write(records, out_interfaces, 'fasta')\n",
    "\n",
    "    # Only non-interfaces\n",
    "    record_1 = SeqRecord(seq = Seq(only_non_interfaces[0]), id = paralog_ID)\n",
    "    record_2 = SeqRecord(seq = Seq(only_non_interfaces[1]), id = paralog_ID_2)\n",
    "    records = [record_1, record_2]\n",
    "    out_non_interfaces = output_012_only_non_interfaces + '/' + P1 + '_' + P2 + '_only_non_interfaces.fasta'\n",
    "    SeqIO.write(records, out_non_interfaces, 'fasta')\n",
    "    \n",
    "    return [out_pdb, out_interfaces, out_non_interfaces]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "handle = open(integrated_table_file, 'r')\n",
    "reader = csv.reader(handle, delimiter = '\\t')\n",
    "\n",
    "new_table = open(output_path + \"/Paralogs_sequence_identities_dist.txt\", 'w')\n",
    "new_table_writer = csv.writer(new_table, delimiter = '\\t')\n",
    "\n",
    "headers = reader.next()\n",
    "headers = headers + [\"Compared_interface\", \"Full_sequence_identity\", \"PDB_sequence_identity\", \"Interface_sequence_identity\", \"Non_interface_sequence_identity\"]\n",
    "new_table_writer.writerow(headers)\n",
    "\n",
    "distance_interface_path = output_006_dist_interfaces\n",
    "interface_dict_path = output_007_interface_dict\n",
    "\n",
    "# Loop through the lines\n",
    "for line in reader:\n",
    "    P1 = line[0]\n",
    "    P2 = line[1]\n",
    "    \n",
    "    # Get the PDB files I need for that pair using the structure dictionary\n",
    "    for complex_type, structure in paralogs2structures[(P1, P2)].items():\n",
    "        \n",
    "        # Get the PDB file that corresponds to this complex\n",
    "        pdb_file = distance_interface_path + 'dist_regions_' + structure[0:4] + '.pdb' \n",
    "\n",
    "        print pdb_file\n",
    "        print P1, P2\n",
    "        \n",
    "        # Parse the interface dictionary if it is a HET\n",
    "        if complex_type == 'HET':\n",
    "            # Retrieve regions from the PDB file\n",
    "            pdb_dict, start_dict, end_dict, pdb_sequence_dict = region_parser(pdb_file, aa_dict)\n",
    "            \n",
    "            # Run first with the first paralog\n",
    "            paralog_ID = P1\n",
    "            paralog_ID_2 = P2\n",
    "            \n",
    "            # Get the phylo IDs to look at the PhylomeDB files\n",
    "            phylo_ID = systematic2phylomeDB[paralog_ID]\n",
    "            phylo_ID_2 = systematic2phylomeDB[paralog_ID_2]\n",
    "            \n",
    "            phylome_dict = fasta2dict(os.path.join(phylomedb_path, phylo_ID + '.raw.fasta'))\n",
    "            \n",
    "            full_region_dict, match_list = first_round_alignments2(phylome_dict, phylo_ID, paralog_ID, alignment_dict, chain_dict)\n",
    "            \n",
    "            record_list = fasta2list(os.path.join(phylomedb_path, phylo_ID + '.raw.fasta'))\n",
    "                                      \n",
    "            # Need to check if the paralog is in the phylome\n",
    "            record_2 = phylome_dict.get(phylo_ID_2, -1)\n",
    "            if type(record_2) != SeqRecord:\n",
    "                record_2 = proteome_dict[paralog_ID_2]\n",
    "            \n",
    "                record_list.append(record_2)\n",
    "            \n",
    "                # Write the records and align\n",
    "                outpath = output_009_phylo_PDB_aln + '/' + P1 + '_' + P2 + '.fasta'\n",
    "                SeqIO.write(record_list, outpath, 'fasta')\n",
    "                pair_align_dict = align_seqs(outpath)\n",
    "                \n",
    "                final_pair_dict = OrderedDict()\n",
    "                \n",
    "                for key, value in pair_align_dict.items():\n",
    "                    if key in (phylo_ID, paralog_ID_2):\n",
    "                        final_pair_dict[key] = value\n",
    "                 \n",
    "                out_files = save_final_sequences2(final_pair_dict, full_region_dict, paralog_ID_2, phylo_ID, aa2three_letter)\n",
    "                \n",
    "                same_phylome = 0\n",
    "                \n",
    "            else:\n",
    "                final_pair_dict = OrderedDict()\n",
    "            \n",
    "                # Extract from that alignment the records for the paralogs \n",
    "                for key, value in phylome_dict.items():\n",
    "                    if key in (phylo_ID, phylo_ID_2):\n",
    "                        final_pair_dict[key] = value\n",
    "            \n",
    "                out_files = save_final_sequences2(final_pair_dict, full_region_dict, phylo_ID_2, phylo_ID, aa2three_letter)\n",
    "            \n",
    "                same_phylome = 1\n",
    "            \n",
    "            # Finally, read sequence similarity\n",
    "            full_seq_ident = percentage_identity2(final_pair_dict)\n",
    "            PDB_seq_ident = percentage_identity(in_file = out_files[0])\n",
    "            interface_seq_ident = percentage_identity(in_file = out_files[1])\n",
    "            non_interface_seq_ident = percentage_identity(in_file = out_files[2])\n",
    "\n",
    "            # Check percentage identity\n",
    "            print 'Full sequence identity:', full_seq_ident\n",
    "            print \"Whole PDB structure:\", PDB_seq_ident\n",
    "            print \"Only interfaces:\", interface_seq_ident\n",
    "            print \"Only non-interfaces:\", non_interface_seq_ident\n",
    "            print '---------'\n",
    "            \n",
    "            new_table_writer.writerow(line + [\"HET_P1\", full_seq_ident, PDB_seq_ident, interface_seq_ident, non_interface_seq_ident, same_phylome])\n",
    "            \n",
    "            # Run with the second one\n",
    "            paralog_ID = P2\n",
    "            paralog_ID_2 = P1\n",
    "            \n",
    "            # I should get the phylo IDs to look at the PhylomeDB files\n",
    "            phylo_ID = systematic2phylomeDB[paralog_ID]\n",
    "            phylo_ID_2 = systematic2phylomeDB[paralog_ID_2]\n",
    "            \n",
    "            phylome_dict = fasta2dict(os.path.join(phylomedb_path, phylo_ID + '.raw.fasta'))\n",
    "            \n",
    "            full_region_dict, match_list = first_round_alignments2(phylome_dict, phylo_ID, paralog_ID, alignment_dict, chain_dict)\n",
    "            \n",
    "            record_list = fasta2list(os.path.join(phylomedb_path, phylo_ID + '.raw.fasta'))\n",
    "                                      \n",
    "            # Need to check if the paralog is in the phylome\n",
    "            record_2 = phylome_dict.get(phylo_ID_2, -1)\n",
    "            if type(record_2) != SeqRecord:\n",
    "                record_2 = proteome_dict[paralog_ID_2]\n",
    "            \n",
    "                record_list.append(record_2)\n",
    "            \n",
    "                # Write the records and align\n",
    "                outpath = output_009_phylo_PDB_aln + '/' + P1 + '_' + P2 + '.fasta'\n",
    "                SeqIO.write(record_list, outpath, 'fasta')\n",
    "                pair_align_dict = align_seqs(outpath)\n",
    "                \n",
    "                final_pair_dict = OrderedDict()\n",
    "                \n",
    "                for key, value in pair_align_dict.items():\n",
    "                    if key in (phylo_ID, paralog_ID_2):\n",
    "                        final_pair_dict[key] = value\n",
    "            \n",
    "                out_files = save_final_sequences2(final_pair_dict, full_region_dict, paralog_ID_2, phylo_ID, aa2three_letter)\n",
    "                \n",
    "                same_phylome = 0\n",
    "                \n",
    "            else:\n",
    "                final_pair_dict = OrderedDict()\n",
    "            \n",
    "                # Extract from that alignment the records for the two paralogs\n",
    "                for key, value in phylome_dict.items():\n",
    "                    if key in (phylo_ID, phylo_ID_2):\n",
    "                        final_pair_dict[key] = value\n",
    "            \n",
    "                out_files = save_final_sequences2(final_pair_dict, full_region_dict, phylo_ID_2, phylo_ID, aa2three_letter)\n",
    "            \n",
    "                same_phylome = 1\n",
    "            \n",
    "            # Finally, read sequence similarity\n",
    "            full_seq_ident = percentage_identity2(final_pair_dict)\n",
    "            PDB_seq_ident = percentage_identity(in_file = out_files[0])\n",
    "            interface_seq_ident = percentage_identity(in_file = out_files[1])\n",
    "            non_interface_seq_ident = percentage_identity(in_file = out_files[2])\n",
    "\n",
    "            # Check percentage identity\n",
    "            print 'Full sequence identity:', full_seq_ident\n",
    "            print \"Whole PDB structure:\", PDB_seq_ident\n",
    "            print \"Only interfaces:\", interface_seq_ident\n",
    "            print \"Only non-interfaces:\", non_interface_seq_ident\n",
    "            print '---------'\n",
    "            new_table_writer.writerow(line + [\"HET_P2\", full_seq_ident, PDB_seq_ident, interface_seq_ident, non_interface_seq_ident, same_phylome])\n",
    "            \n",
    "        else:\n",
    "            # Retrieve regions from the PDB file\n",
    "            pdb_dict, start_dict, end_dict, pdb_sequence_dict = region_parser(pdb_file, aa_dict)\n",
    "            \n",
    "            # As these are HM, get the sequence from any of them\n",
    "            pdb_sequence = pdb_sequence_dict.values()[0]\n",
    "            \n",
    "            if complex_type == 'P1_HM':  \n",
    "                paralog_ID = P1\n",
    "                paralog_ID_2 = P2\n",
    "            elif complex_type == 'P2_HM':\n",
    "                paralog_ID = P2\n",
    "                paralog_ID_2 = P1\n",
    "\n",
    "            # Get the phylo IDs to look at the PhylomeDB files\n",
    "            phylo_ID = systematic2phylomeDB[paralog_ID]\n",
    "            phylo_ID_2 = systematic2phylomeDB[paralog_ID_2]\n",
    "            \n",
    "            phylome_dict = fasta2dict(os.path.join(phylomedb_path, phylo_ID + '.raw.fasta'))\n",
    "            \n",
    "            full_region_dict, match_list = first_round_alignments2(phylome_dict, phylo_ID, paralog_ID, alignment_dict, chain_dict)\n",
    "            \n",
    "            record_list = fasta2list(os.path.join(phylomedb_path, phylo_ID + '.raw.fasta'))\n",
    "                                      \n",
    "            # Need to check if the paralog is in the phylome\n",
    "            record_2 = phylome_dict.get(phylo_ID_2, -1)\n",
    "            if type(record_2) != SeqRecord:\n",
    "                record_2 = proteome_dict[paralog_ID_2]\n",
    "            \n",
    "                record_list.append(record_2)\n",
    "            \n",
    "                # Write the records and align\n",
    "                outpath = output_009_phylo_PDB_aln + '/' + P1 + '_' + P2 + '.fasta'\n",
    "                SeqIO.write(record_list, outpath, 'fasta')\n",
    "                pair_align_dict = align_seqs(outpath)\n",
    "                \n",
    "                final_pair_dict = OrderedDict()\n",
    "                \n",
    "                for key, value in pair_align_dict.items():\n",
    "                    if key in (phylo_ID, paralog_ID_2):\n",
    "                        final_pair_dict[key] = value\n",
    "                        print key\n",
    "                \n",
    "                out_files = save_final_sequences2(final_pair_dict, full_region_dict, paralog_ID_2, phylo_ID, aa2three_letter)\n",
    "                \n",
    "                same_phylome = 0\n",
    "                \n",
    "            else:\n",
    "                final_pair_dict = OrderedDict()\n",
    "            \n",
    "                # Extract from that alignment the records for the two paralogs\n",
    "                for key, value in phylome_dict.items():\n",
    "                    if key in (phylo_ID, phylo_ID_2):\n",
    "                        final_pair_dict[key] = value\n",
    "                        print key\n",
    "            \n",
    "                out_files = save_final_sequences2(final_pair_dict, full_region_dict, phylo_ID_2, phylo_ID, aa2three_letter)\n",
    "                \n",
    "                same_phylome = 1\n",
    "                \n",
    "            # Finally, read sequence similarity\n",
    "            full_seq_ident = percentage_identity2(final_pair_dict)\n",
    "            PDB_seq_ident = percentage_identity(in_file = out_files[0])\n",
    "            interface_seq_ident = percentage_identity(in_file = out_files[1])\n",
    "            non_interface_seq_ident = percentage_identity(in_file = out_files[2])\n",
    "            \n",
    "            # Check percentage identity\n",
    "            print 'Full sequence identity:', full_seq_ident\n",
    "            print \"Whole PDB structure:\", PDB_seq_ident\n",
    "            print \"Only interfaces:\", interface_seq_ident\n",
    "            print \"Only non-interfaces:\", non_interface_seq_ident\n",
    "            print '---------'\n",
    "            new_table_writer.writerow(line + [complex_type, full_seq_ident, PDB_seq_ident, interface_seq_ident, non_interface_seq_ident, same_phylome])\n",
    "            \n",
    "handle.close()\n",
    "new_table.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that gets the length of the matching chain in the PDB structure\n",
    "def get_PDB_length(path_to_pdb_file, chain_query):\n",
    "    '''\n",
    "    A function designed to count the number of residues in a particular chain in a PDB structure.\n",
    "    '''\n",
    "    structure = parser.get_structure(path_to_pdb_file, path_to_pdb_file)\n",
    "    \n",
    "    res_no = 0\n",
    "    \n",
    "    for model in structure:\n",
    "        for chain in model:\n",
    "            if chain.get_id() == chain_query:\n",
    "                for residue in chain.get_residues():\n",
    "                    if residue.id[0] == ' ':\n",
    "                        res_no +=1\n",
    "                \n",
    "    return(res_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = PDBParser()\n",
    "\n",
    "handle = open(os.path.join(output_path, \"Paralogs_sequence_identities_dist_2019-06-19.txt\"), 'r')\n",
    "reader = csv.reader(handle, delimiter = '\\t')\n",
    "\n",
    "out_handle = open(os.path.join(output_path, \"Paralogs_sequence_identities_dist_completeness_2019-06-19.txt\"), 'w')\n",
    "writer = csv.writer(out_handle, delimiter = '\\t')\n",
    "\n",
    "for entry in reader:\n",
    "    P1 = entry[0]\n",
    "    P2 = entry[1]\n",
    "    \n",
    "    # Skip header\n",
    "    if P1 == 'P1_ID':\n",
    "        header = entry\n",
    "        header.append('PDB_length')\n",
    "        header.append('Full_protein_length')\n",
    "        writer.writerow(header)\n",
    "        continue\n",
    "       \n",
    "    compared_struc = entry[10]\n",
    "    \n",
    "    # Now that I have the dictionary, I can use it to select the best isoforms\n",
    "    if compared_struc == 'P1_HM' or compared_struc == 'HET_P1':\n",
    "    \n",
    "        # Add the length of the protein chain from the PDB structure\n",
    "        if compared_struc == 'P1_HM':\n",
    "            pdb_structure = entry[8]\n",
    "        elif 'HET_P1':\n",
    "            pdb_structure = entry[5]\n",
    "            \n",
    "        matching_chain = alignment_dict[(P1, P2)][P1][pdb_structure[0:4]][0]\n",
    "        \n",
    "        protein_path = output_004_bio_assemblies + pdb_structure + '.pdb'\n",
    "        \n",
    "        pdb_length = get_PDB_length(protein_path, matching_chain)\n",
    "        \n",
    "        # Add the length of the full protein from the reference proteome\n",
    "        full_protein_length = len(proteome_dict[P1].seq)\n",
    "    \n",
    "    elif compared_struc == 'P2_HM' or compared_struc == 'HET_P2':         \n",
    "        # Add the length of the protein chain from the PDB structure\n",
    "        if compared_struc == 'P2_HM':\n",
    "            pdb_structure = entry[9]\n",
    "        elif 'HET_P2':\n",
    "            pdb_structure = entry[5]\n",
    "            \n",
    "        matching_chain = alignment_dict[(P1, P2)][P2][pdb_structure[0:4]][0]\n",
    "        \n",
    "        protein_path = output_004_bio_assemblies + pdb_structure + '.pdb'\n",
    "        \n",
    "        pdb_length = get_PDB_length(protein_path, matching_chain)\n",
    "        \n",
    "        # Add the length of the full protein from the reference proteome\n",
    "        full_protein_length = len(proteome_dict[P2].seq)\n",
    "    \n",
    "    new_line = entry\n",
    "    new_line.append(pdb_length)\n",
    "    new_line.append(full_protein_length)\n",
    "    writer.writerow(new_line)\n",
    "                \n",
    "            \n",
    "handle.close()\n",
    "out_handle.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
