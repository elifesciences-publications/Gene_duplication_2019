{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gather PDB info\n",
    "\n",
    "This script will create a table summarizing the information I can get from the PDB files. Such a final table will have the following columns:\n",
    "\n",
    "- P1_ID\n",
    "- P2_ID\n",
    "- Duplication type\n",
    "- Monomer_P1 (the ID of a PDB structure that shows the P1 monomer or NA if there is none in my set)\n",
    "- Monomer_P2 (the ID of a PDB structure that shows the P2 monomer or NA if there is none in my set)\n",
    "- HM_P1 (the ID of a PDB structure whose biological assembly is not a monomer AND has at least two copies of P1)\n",
    "- HM_P2 (the ID of a PDB structure whose biological assembly is not a monomer AND has at least two copies of P2)\n",
    "- HET (the ID of a PDB structure whose biological assembly is not a monomer AND has at least one copy of each of P1 and P2)\n",
    "- P1_unspecific (1 if P1 is in the list of structures with unspecific interactions in Tarassov's data, 0 otherwise)\n",
    "- P2_unspecific (1 if P2 is in the list of structures with unspecific interactions in Tarassov's data, 0 otherwise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import csv\n",
    "import glob\n",
    "import re\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A folder to write the output\n",
    "output_path = <path/to/output>\n",
    "\n",
    "# A folder with the PDB files downloaded from the alignments\n",
    "pdb_folder = <path/to/pdb/folder>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Working with the information from the PDB files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict_text_2_numbers = {\n",
    "     'MONOMERIC': 1, \n",
    "     'DIMERIC': 2,\n",
    "     'TRIMERIC': 3,\n",
    "     'TETRAMERIC': 4,\n",
    "     'PENTAMERIC': 5,\n",
    "     'HEXAMERIC': 6,\n",
    "     'HEPTAMERIC': 7,\n",
    "     'OCTAMERIC': 8,\n",
    "     'NONAMERIC': 9,\n",
    "     'DECAMERIC': 10,\n",
    "     'UNDECAMERIC': 11,\n",
    "     'DODECAMERIC': 12,\n",
    "     'TRIDECAMERIC': 13,\n",
    "     'TETRADECAMERIC': 14,\n",
    "     'PENTADECAMERIC': 15,\n",
    "     'HEXADECAMERIC': 16,\n",
    "     'HEPTADECAMERIC': 17,\n",
    "     'OCTADECAMERIC': 18,\n",
    "     'NONADECAMERIC': 19,\n",
    "     'EICOSAMERIC': 20\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_pdb_data(pdb_file, dict_text_2_numbers):\n",
    "    '''This function will receive the path to a PDB file and extract its information as a list with:\n",
    "    - The PDB ID\n",
    "    - The biological assembly assigned by the authors\n",
    "    - The total number of subunits in that assembly\n",
    "    - The structure's resolution, if applicable\n",
    "    - A dictionary containing the IDs of those chains and how many times they appear in the assembly\n",
    "    '''\n",
    "    handle = open(pdb_file, 'r')\n",
    "    pdb_id = pdb_file.split('/')[-1][0:4]\n",
    "    resolution = 'NA'\n",
    "    quit_bool = False\n",
    "    \n",
    "    # This dictionary will save how many times each chain is found in the selected biological assembly\n",
    "    chains_dict = OrderedDict()\n",
    "    \n",
    "    # Loop through the lines to look for REMARK 350\n",
    "    for line in handle:\n",
    "        if line.startswith('EXPDTA'):\n",
    "            # Split the line on the experimental data with at least two spaces\n",
    "            expdata = re.split(' [ ]+', line)[1]    \n",
    "        if line.startswith('REMARK   2 RESOLUTION.'):\n",
    "            # Extract the resolution\n",
    "            res_match = re.search('([0-9\\.]+)[ ]+ANGSTROM', line)\n",
    "            if res_match:\n",
    "                resolution = res_match.group(1)\n",
    "        if line.startswith('REMARK 350'):\n",
    "\n",
    "            # Stop reading on the one that was determined by the authors\n",
    "            match_assembly = re.search('BIOMOLECULE:[ ]+([0-9]+)', line)\n",
    "            if match_assembly:   \n",
    "                if quit_bool:\n",
    "\n",
    "                    subunit_number = dict_text_2_numbers.get(subunit_number, subunit_number)\n",
    "                    return [pdb_id, bio_assembly, subunit_number, expdata, resolution, chains_dict]\n",
    "                else:\n",
    "                    \n",
    "                    bio_assembly = int(match_assembly.group(1))\n",
    "            \n",
    ".\n",
    "            match_author = re.search('AUTHOR DETERMINED BIOLOGICAL UNIT: ([a-zA-Z0-9]+)', line)\n",
    "            if match_author:\n",
    "                subunit_number = match_author.group(1)\n",
    "                \n",
    "                quit_bool = True\n",
    "            \n",
    "            # Check which chains are in this biological assembly\n",
    "            match_chains_1 = re.search('APPLY THE FOLLOWING TO CHAINS: ([a-zA-Z0-9, ]+)', line)\n",
    "            if match_chains_1:\n",
    "                chains_assembly = match_chains_1.group(1).strip()\n",
    "            \n",
    "            # Sometimes the chains don't fit in a single line (example: 2ja7)\n",
    "            match_chains_2 = re.search('AND CHAINS: ([a-zA-Z0-9, ]+)', line)\n",
    "            if match_chains_2:\n",
    "                chains_assembly = chains_assembly + ' ' + match_chains_2.group(1).strip()\n",
    "            \n",
    "            # Sometimes a single chain is used to obtain two chains (example: 3qps)\n",
    "            # Look for the BIOMT line\n",
    "            match_biomt = re.search('BIOMT\\d   (\\d)', line)\n",
    "            if match_biomt:\n",
    "                all_chains = chains_assembly.split(', ')\n",
    "                for chain in all_chains:\n",
    "                    chains_dict[chain] = int(match_biomt.group(1))\n",
    "            \n",
    "            \n",
    "    # Structures without biological assemblies will be considered monomeric\n",
    "    if quit_bool:\n",
    "        # Make sure I convert the assembly types from text to numbers\n",
    "        subunit_number = dict_text_2_numbers.get(subunit_number, subunit_number)\n",
    "        return [pdb_id, bio_assembly, subunit_number, expdata, resolution, chains_dict]\n",
    "    else:\n",
    "        return [pdb_id, 1, 1, expdata, resolution, chains_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loop through all the structures to extract these data\n",
    "file_list = glob.glob(pdb_folder + '/*pdb')\n",
    "handle_out = open(output_path + '/PDB_structures.txt', 'w')\n",
    "structure_dict = OrderedDict()\n",
    "\n",
    "\n",
    "for pdb_file in file_list:\n",
    "    new_line = extract_pdb_data(pdb_file, dict_text_2_numbers)\n",
    "    \n",
    "    # The key will be the PDB ID and everything else will be in the values\n",
    "    structure_dict[new_line[0]] = new_line[1:6]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the alignment data as a dictionary\n",
    "alignment_dict = OrderedDict()\n",
    "handle_in = open('Data/PDB_matches_all_chains_SSD_WGD.txt', 'r')\n",
    "reader = csv.reader(handle_in, delimiter = '\\t')\n",
    "\n",
    "unspecific_dict = OrderedDict()\n",
    "dup_type_dict = OrderedDict()\n",
    "\n",
    "for line in reader:\n",
    "    P1 = line[0]\n",
    "    P2 = line[14]\n",
    "    pair_list = [P1, P2]\n",
    "    pair_list.sort()\n",
    "    pair = tuple(pair_list)\n",
    "    \n",
    "    P1_match_PDB = line[1]\n",
    "    P1_match_chain = line[2]\n",
    "    \n",
    "    P1_unspecific = line[15]\n",
    "    P2_unspecific = line[16]\n",
    "    \n",
    "    dup_type = line[17]\n",
    "    \n",
    "    # Save the data about unspecific interactions and duplication types\n",
    "    unspecific_dict[P1] = P1_unspecific\n",
    "    unspecific_dict[P2] = P2_unspecific\n",
    "    \n",
    "    dup_type_dict[pair] = dup_type\n",
    "    \n",
    "    # Skip the first line\n",
    "    if P1 == 'P1':\n",
    "        continue\n",
    "    \n",
    "    # Start filling the dictionary\n",
    "    if alignment_dict.get(pair, -1) == -1:\n",
    "        # First level\n",
    "        alignment_dict[pair] = OrderedDict()\n",
    "        \n",
    "        # Second level\n",
    "        alignment_dict[pair][P1] = OrderedDict()\n",
    "        alignment_dict[pair][P2] = OrderedDict()\n",
    "        \n",
    "        # Third level\n",
    "        alignment_dict[pair][P1][P1_match_PDB] = [P1_match_chain]\n",
    "    \n",
    "    # For new PDB structures for paralogs that were already added\n",
    "    elif alignment_dict[pair][P1].get(P1_match_PDB, -1) == -1:\n",
    "        alignment_dict[pair][P1][P1_match_PDB] = [P1_match_chain]\n",
    "        \n",
    "    # Append the chain to the list of chains\n",
    "    else:\n",
    "        alignment_dict[pair][P1][P1_match_PDB].append(P1_match_chain)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "handle_out = open(output_path + '/paralogs_PDB_structures_complete2.txt', 'w')\n",
    "writer = csv.writer(handle_out, delimiter = '\\t')\n",
    "header = ['P1_ID', 'P2_ID', 'Duplication_type','Monomer_P1', 'Monomer_P2', 'HM_P1', 'HM_P2', 'HET', 'other_HET_P1', 'other_HET_P2', 'P1_unspecific', 'P2_unspecific']\n",
    "writer.writerow(header)\n",
    "\n",
    "# Loop through the pairs of paralogs\n",
    "for pair in alignment_dict.keys():\n",
    "    P1 = pair[0]\n",
    "    P2 = pair[1]\n",
    "    \n",
    "    dup_type = dup_type_dict[pair]\n",
    "    P1_unspecific = unspecific_dict[P1]\n",
    "    P2_unspecific = unspecific_dict[P2]\n",
    "\n",
    "    monomers_P1_list = []\n",
    "    monomers_P2_list = []\n",
    "    HM_P1_list = []\n",
    "    HM_P2_list = []\n",
    "    other_HET_P1_list = []\n",
    "    other_HET_P2_list = []\n",
    "    HET_list = []\n",
    "    \n",
    "    for structure, chains in alignment_dict[pair][P1].items():\n",
    "        \n",
    "        # Skip structures that were solved with solution NMR\n",
    "        if structure_dict[structure][2] == 'SOLUTION NMR':\n",
    "            continue\n",
    "        elif len(structure_dict[structure][4].keys()) == 0:\n",
    "            matches_in_structure = len(chains)\n",
    "        else:\n",
    "            matches_in_structure = 0\n",
    "            for chain in chains:\n",
    "                # Check the number of chains in the assembly that derive from this chain\n",
    "                chain_matches = structure_dict[structure][4].get(chain, 0)\n",
    "                matches_in_structure = matches_in_structure + chain_matches\n",
    "        \n",
    "        # Check if this is a monomer (the assembly has only one chain AND there is one match)\n",
    "        if structure_dict[structure][1] == 1 and matches_in_structure == 1:\n",
    "            \n",
    "            monomer_P1 = structure + '_' + str(structure_dict[structure][0])\n",
    "            monomers_P1_list.append(monomer_P1)\n",
    "        # Check if this is a HM (the assembly has more than one chain AND this paralog matches more than one chain)\n",
    "        elif structure_dict[structure][1] > 1 and matches_in_structure > 1:\n",
    "            HM_P1 = structure + '_' + str(structure_dict[structure][0])\n",
    "            HM_P1_list.append(HM_P1)\n",
    "        # Check if this is a HET but not of paralogs (other_HET)\n",
    "        elif structure_dict[structure][1] > 1 and matches_in_structure == 1:\n",
    "            other_HET_P1 = structure + '_' + str(structure_dict[structure][0])\n",
    "            other_HET_P1_list.append(other_HET_P1)\n",
    "    \n",
    "    # Work with P2 and the list of structures whose chains match it\n",
    "    for structure, chains in alignment_dict[pair][P2].items():\n",
    "        \n",
    "        # Skip structures that were solved with solution NMR\n",
    "        if structure_dict[structure][2] == 'SOLUTION NMR':\n",
    "            continue\n",
    "        elif len(structure_dict[structure][4].keys()) == 0:\n",
    "            matches_in_structure = len(chains)\n",
    "        else:\n",
    "            matches_in_structure = 0\n",
    "            for chain in chains:\n",
    "                # Check the number of chains in the assembly that derive from this chain\n",
    "                chain_matches = structure_dict[structure][4].get(chain, 0)\n",
    "                matches_in_structure = matches_in_structure + chain_matches\n",
    "            \n",
    "        # Check if this is a monomer (the assembly has only one chain AND there is only one match)\n",
    "        if structure_dict[structure][1] == 1 and matches_in_structure == 1:\n",
    "            \n",
    "            monomer_P2 = structure + '_' + str(structure_dict[structure][0])\n",
    "            monomers_P2_list.append(monomer_P2)\n",
    "        # Check if this is a HM (the assembly has more than one chain AND this paralog matches more than one chain)\n",
    "        elif structure_dict[structure][1] > 1 and matches_in_structure > 1:\n",
    "            HM_P2 = structure + '_' + str(structure_dict[structure][0])\n",
    "            HM_P2_list.append(HM_P2)\n",
    "        # Check if this is a HET but not of paralogs (other_HET)\n",
    "        elif structure_dict[structure][1] > 1 and matches_in_structure == 1:\n",
    "            other_HET_P2 = structure + '_' + str(structure_dict[structure][0])\n",
    "            other_HET_P2_list.append(other_HET_P2)\n",
    "    \n",
    "    # Get the list of HET\n",
    "    # Start with the list of structures that have a match of P1 and P2\n",
    "    P1_matches = alignment_dict[pair][P1].keys()\n",
    "    P2_matches = alignment_dict[pair][P2].keys()\n",
    "    \n",
    "    # Loop through each of the structures in P1_matches and check if it also has matches for P2\n",
    "    for candidate in P1_matches:\n",
    "        if candidate in P2_matches:\n",
    "            chains_P1 = alignment_dict[pair][P1][candidate]\n",
    "            chains_P2 = alignment_dict[pair][P2][candidate]\n",
    "            total_chains = structure_dict[candidate][1]\n",
    "            assembly = structure_dict[candidate][0]\n",
    "            \n",
    "            chains_P1_match = 0\n",
    "            if len(structure_dict[candidate][4].keys()) == 0:\n",
    "                chains_P1_match = len(chains_P1)\n",
    "            else:\n",
    "                for chain in chains_P1:\n",
    "                    P1_chain_matches = structure_dict[candidate][4].get(chain, 0)\n",
    "                    chains_P1_match = chains_P1_match + P1_chain_matches \n",
    "\n",
    "            chains_P2_match = 0\n",
    "            if len(structure_dict[candidate][4].keys()) == 0:\n",
    "                chains_P2_match = len(chains_P2)\n",
    "            else:\n",
    "                for chain in chains_P2:\n",
    "                    P2_chain_matches = structure_dict[candidate][4].get(chain, 0)\n",
    "                    chains_P2_match = chains_P2_match + P2_chain_matches             \n",
    "            \n",
    "            # Check if:\n",
    "            # There is at least one match for P1 AND \n",
    "            # There is at least one match for P2 AND\n",
    "            # The assembly has at least as many subunits as the sum of matches of P1 and P2\n",
    "            if chains_P1_match >= 1 and chains_P2_match >= 1 and total_chains >= (chains_P1_match + chains_P2_match):\n",
    "                HET = candidate + '_' + str(assembly)\n",
    "                HET_list.append(HET)\n",
    "                # Remove these HET from the other_HET category if they are there\n",
    "                if HET in other_HET_P1_list:\n",
    "                    other_HET_P1_list.remove(HET)\n",
    "                if HET in other_HET_P2_list:\n",
    "                    other_HET_P2_list.remove(HET)\n",
    "    \n",
    "    # Assemble the table\n",
    "    save_bool = False\n",
    "    if len(monomers_P1_list) == 0:\n",
    "        monomers_P1 = 'NA'\n",
    "    else:\n",
    "        monomers_P1 = ','.join(monomers_P1_list)\n",
    "        save_bool = True\n",
    "        \n",
    "    if len(monomers_P2_list) == 0:\n",
    "        monomers_P2 = 'NA'\n",
    "    else:    \n",
    "        monomers_P2 = ','.join(monomers_P2_list)\n",
    "        save_bool = True\n",
    "        \n",
    "    if len(HM_P1_list) == 0:\n",
    "        HM_P1 = 'NA'\n",
    "    else:\n",
    "        HM_P1 = ','.join(HM_P1_list)\n",
    "        save_bool = True\n",
    "        \n",
    "    if len(HM_P2_list) == 0:\n",
    "        HM_P2 = 'NA'\n",
    "    else:\n",
    "        HM_P2 = ','.join(HM_P2_list)\n",
    "        save_bool = True\n",
    "        \n",
    "    if len(HET_list) == 0:\n",
    "        HET = 'NA'\n",
    "    else:\n",
    "        HET = ','.join(HET_list)\n",
    "        save_bool = True\n",
    "        \n",
    "    if len(other_HET_P1_list) == 0:\n",
    "        other_HET_P1 = 'NA'\n",
    "    else:\n",
    "        other_HET_P1 = ','.join(other_HET_P1_list)\n",
    "        save_bool = True\n",
    "        \n",
    "    if len(other_HET_P2_list) == 0:\n",
    "        other_HET_P2 = 'NA'\n",
    "    else:\n",
    "        other_HET_P2 = ','.join(other_HET_P2_list)\n",
    "        save_bool = True\n",
    "        \n",
    "    # Now, I can put everything together and write the new row\n",
    "    if save_bool == True:\n",
    "        new_row = [P1, P2, dup_type, monomers_P1, monomers_P2, HM_P1, HM_P2, HET, other_HET_P1, other_HET_P2, P1_unspecific, P2_unspecific]\n",
    "        writer.writerow(new_row)\n",
    "\n",
    "handle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look for strict homomers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the final data table\n",
    "handle = open(output_path + '/paralogs_PDB_structures_complete2.txt', 'r')\n",
    "table_reader = csv.reader(handle, delimiter = '\\t')\n",
    "\n",
    "# Skip headers\n",
    "header = table_reader.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the final data table\n",
    "handle = open(output_path +'/paralogs_PDB_structures_complete2.txt', 'r')\n",
    "table_reader = csv.reader(handle, delimiter = '\\t')\n",
    "\n",
    "# Skip headers\n",
    "header = table_reader.next()\n",
    "\n",
    "# Prepare the file to write\n",
    "handle_writer = open(output_path + '/paralogs_PDB_structures_with_strict2.txt', 'w')\n",
    "writer = csv.writer(handle_writer, delimiter = '\\t')\n",
    "\n",
    "header = ['P1_ID', 'P2_ID', 'Duplication_type','Monomer_P1', 'Monomer_P2', 'HM_P1', 'HM_P2', 'HET', 'other_HET_P1', 'other_HET_P2', 'P1_unspecific', 'P2_unspecific', 'Strict_HM_P1', 'Strict_HM_P2']   \n",
    "writer.writerow(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for line in table_reader:\n",
    "    \n",
    "    paralog_1 = line[0]\n",
    "    paralog_2 = line[1]\n",
    "    HM_1 = line[5]\n",
    "    HM_2 = line[6]\n",
    "    HET = line[7]\n",
    "    strict_HM_1 = []\n",
    "    strict_HM_2 = []\n",
    "    \n",
    "    HM_1 = HM_1.split(',')\n",
    "    HM_2 = HM_2.split(',')\n",
    "\n",
    "    if HM_1[0] == 'NA':\n",
    "        line.append('NA')\n",
    "    else:\n",
    "        # Look at each of the structures in HM_1 and HM_2 and their chains based on the\n",
    "        # alignment and structure dictionaries.\n",
    "        for structure in HM_1:\n",
    "            # Check which chains in that structure correspond to paralog 1\n",
    "            chains = alignment_dict[(paralog_1, paralog_2)][paralog_1][structure[0:4]]\n",
    "            # Get the total number of chains that come from those chains\n",
    "            total = 0\n",
    "\n",
    "            for chain in chains:\n",
    "                # Get the total number of times this chain appears in the biological assembly\n",
    "                # Some might not appear because they could be present in the file but in a different assembly\n",
    "                chain_appears = structure_dict[structure[0:4]][4].get(chain,0)\n",
    "\n",
    "                # Count the total number of chains\n",
    "                total = total + chain_appears\n",
    "\n",
    "            # Check if it is a strict HM. This would be the case if all the chains that form the structure were matches\n",
    "            if total == structure_dict[structure[0:4]][1]:\n",
    "                # Then we have a strict HM for paralog 1\n",
    "                strict_HM_1.append(structure)\n",
    "        \n",
    "        # Now, add the data on strict homomers to the line and write to a file\n",
    "        # If there are strict homomers write them to the column. Otherwise, write NA.\n",
    "        if len(strict_HM_1) > 0:\n",
    "            strict_HM_1_final = ','.join(strict_HM_1)\n",
    "            line.append(strict_HM_1_final)\n",
    "        else:\n",
    "            line.append('NA')\n",
    "\n",
    "    # Repeat for HM_2\n",
    "    if HM_2[0] == 'NA':\n",
    "        line.append('NA')\n",
    "    else:\n",
    "        for structure in HM_2:\n",
    "            # Check which chains in that structure correspond to paralog 2\n",
    "            chains = alignment_dict[(paralog_1, paralog_2)][paralog_2][structure[0:4]]\n",
    "            # Get the total number of chains that come from those chains\n",
    "            total = 0\n",
    "\n",
    "            for chain in chains:\n",
    "                # Get the total number of times this chain appears in the biological assembly\n",
    "                # Some might not appear because they could be present in the file but in a different assembly\n",
    "                chain_appears = structure_dict[structure[0:4]][4].get(chain, 0)\n",
    "\n",
    "                # Count the total number of chains\n",
    "                total = total + chain_appears \n",
    "\n",
    "            # Check if it is a strict HM. This would be the case if all the chains that form the structure were matches\n",
    "            if total == structure_dict[structure[0:4]][1]:\n",
    "                # Then we have a strict HM for paralog 2\n",
    "                strict_HM_2.append(structure)\n",
    "\n",
    "        if len(strict_HM_2) > 0:\n",
    "            strict_HM_2_final = ','.join(strict_HM_2)\n",
    "            line.append(strict_HM_2_final)\n",
    "        else:\n",
    "            line.append('NA')\n",
    "    \n",
    "    writer.writerow(line)\n",
    "\n",
    "handle_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the complexes with the best resolution for interface analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "handle = open(output_path + '/paralogs_PDB_structures_with_strict2.txt', 'r')\n",
    "reader = csv.reader(handle, delimiter = '\\t')\n",
    "\n",
    "handle_writer = open(output_path + '/paralogs_PDB_structures_best_structures2.txt', 'w')\n",
    "writer = csv.writer(handle_writer, delimiter = '\\t')\n",
    "\n",
    "header = ['P1_ID', 'P2_ID', 'Duplication_type', 'HM_P1', 'HM_P2', 'HET', 'P1_unspecific', 'P2_unspecific', 'Strict_HM_P1', 'Strict_HM_P2']   \n",
    "writer.writerow(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Skip the first line\n",
    "header = reader.next()\n",
    "\n",
    "for line in reader:\n",
    "    P1_ID = line[0]\n",
    "    P2_ID = line[1]\n",
    "    dup_type = line[2]\n",
    "    \n",
    "    HM_P1 = line[5]\n",
    "    best_HM_P1 = ['NA', 1000]\n",
    "    \n",
    "    HM_P2 = line[6]\n",
    "    best_HM_P2 = ['NA', 1000]\n",
    "    \n",
    "    HET = line[7]\n",
    "    best_HET = ['NA', 1000]\n",
    "    \n",
    "    P1_unspecific = line[10]\n",
    "    P2_unspecific = line[11]\n",
    "    \n",
    "    strict_HM_P1 = line[12]\n",
    "    best_strict_HM_P1 = ['NA', 1000]\n",
    "    \n",
    "    strict_HM_P2 = line[13]\n",
    "    best_strict_HM_P2 = ['NA', 1000]\n",
    "    \n",
    "    bool_save = False\n",
    "    \n",
    "    # Look at the list of structures in each column, and select the crystal with the best resolution\n",
    "    if HM_P1 != 'NA':\n",
    "        for structure in HM_P1.split(','):\n",
    "            # Get the resolution of such structure if it is a crystal\n",
    "            structure_info = structure_dict[structure[0:4]]\n",
    "            technique = structure_info[2]\n",
    "            resolution = float(structure_info[3])\n",
    "            if technique == 'X-RAY DIFFRACTION' and resolution < best_HM_P1[1]:\n",
    "                best_HM_P1 = [structure, resolution]\n",
    "                bool_save = True\n",
    "    \n",
    "    \n",
    "    if HM_P2 != 'NA':\n",
    "        for structure in HM_P2.split(','):\n",
    "            # Get the resolution of such structure if it is a crystal\n",
    "            structure_info = structure_dict[structure[0:4]]\n",
    "            technique = structure_info[2]\n",
    "            resolution = float(structure_info[3])\n",
    "            if technique == 'X-RAY DIFFRACTION' and resolution < best_HM_P2[1]:\n",
    "                best_HM_P2 = [structure, resolution]\n",
    "                bool_save = True\n",
    "                \n",
    "    if HET != 'NA':\n",
    "        for structure in HET.split(','):\n",
    "            # Get the resolution of such structure if it is a crystal\n",
    "            structure_info = structure_dict[structure[0:4]]\n",
    "            technique = structure_info[2]\n",
    "            resolution = float(structure_info[3])\n",
    "            if technique == 'X-RAY DIFFRACTION' and resolution < best_HET[1]:\n",
    "                best_HET = [structure, resolution]\n",
    "                bool_save = True\n",
    "            \n",
    "    if strict_HM_P1 != 'NA':\n",
    "        for structure in strict_HM_P1.split(','):\n",
    "            # Get the resolution of such structure if it is a crystal\n",
    "            structure_info = structure_dict[structure[0:4]]\n",
    "            technique = structure_info[2]\n",
    "            resolution = float(structure_info[3])\n",
    "            if technique == 'X-RAY DIFFRACTION' and resolution < best_strict_HM_P1[1]:\n",
    "                best_strict_HM_P1 = [structure, resolution]\n",
    "                bool_save = True\n",
    "            \n",
    "    if strict_HM_P2 != 'NA':\n",
    "        for structure in strict_HM_P2.split(','):\n",
    "            # Get the resolution of such structure if it is a crystal\n",
    "            structure_info = structure_dict[structure[0:4]]\n",
    "            technique = structure_info[2]\n",
    "            resolution = float(structure_info[3])\n",
    "            if technique == 'X-RAY DIFFRACTION' and resolution < best_strict_HM_P2[1]:\n",
    "                best_strict_HM_P2 = [structure, resolution]\n",
    "                bool_save = True\n",
    "                \n",
    "    # Now that we have all of them, write the info to the table\n",
    "    if bool_save:\n",
    "        new_row = [P1_ID, P2_ID, dup_type, best_HM_P1[0], best_HM_P2[0], best_HET[0], P1_unspecific, P2_unspecific, best_strict_HM_P1[0], best_strict_HM_P2[0]]\n",
    "        writer.writerow(new_row)\n",
    "        \n",
    "handle_writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
