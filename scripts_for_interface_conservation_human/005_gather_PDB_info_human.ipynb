{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interface conservation analyses human structure selection\n",
    "\n",
    "This is the script that will look at the alignment to the PDB and look for the best available structures that represent each kind of complex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import csv\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "from collections import OrderedDict\n",
    "import math\n",
    "from Bio.PDB import *\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import *\n",
    "from Bio.SeqRecord import *\n",
    "from Bio.Align.Applications import MuscleCommandline\n",
    "from shutil import copyfile\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A folder to write the output\n",
    "output_path = <path/to/output>\n",
    "\n",
    "# A folder with the PDB files downloaded from the alignments\n",
    "pdb_folder = <path/to/pdb/folder>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.- Look for the best available structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_text_2_numbers = {\n",
    "     'MONOMERIC': 1, \n",
    "     'DIMERIC': 2,\n",
    "     'TRIMERIC': 3,\n",
    "     'TETRAMERIC': 4,\n",
    "     'PENTAMERIC': 5,\n",
    "     'HEXAMERIC': 6,\n",
    "     'HEPTAMERIC': 7,\n",
    "     'OCTAMERIC': 8,\n",
    "     'NONAMERIC': 9,\n",
    "     'DECAMERIC': 10,\n",
    "     'UNDECAMERIC': 11,\n",
    "     'DODECAMERIC': 12,\n",
    "     'TRIDECAMERIC': 13,\n",
    "     'TETRADECAMERIC': 14,\n",
    "     'PENTADECAMERIC': 15,\n",
    "     'HEXADECAMERIC': 16,\n",
    "     'HEPTADECAMERIC': 17,\n",
    "     'OCTADECAMERIC': 18,\n",
    "     'NONADECAMERIC': 19,\n",
    "     'EICOSAMERIC': 20\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pdb_data(pdb_file, dict_text_2_numbers):\n",
    "    '''This function will receive the path to a PDB file and extract its information as a list with:\n",
    "    - The PDB ID\n",
    "    - The biological assembly assigned by the authors\n",
    "    - The total number of subunits in that assembly\n",
    "    - The structure's resolution, if applicable\n",
    "    - A dictionary containing the IDs of those chains and how many times they appear in the assembly\n",
    "    '''\n",
    "    handle = open(pdb_file, 'r')\n",
    "    pdb_id = pdb_file.split('/')[-1][0:4]\n",
    "    resolution = 'NA'\n",
    "    quit_bool = False\n",
    "    \n",
    "    # This dictionary will save many times each chain is found in the selected biological assembly\n",
    "    chains_dict = OrderedDict()\n",
    "    \n",
    "    # Loop through the lines to look for REMARK 350\n",
    "    for line in handle:\n",
    "        if line.startswith('EXPDTA'):\n",
    "            # Split the line on the experimental data with at least two spaces\n",
    "            expdata = re.split(' [ ]+', line)[1]    \n",
    "        if line.startswith('REMARK   2 RESOLUTION.'):\n",
    "            # Extract the resolution\n",
    "            res_match = re.search('([0-9\\.]+)[ ]+ANGSTROM', line)\n",
    "            if res_match:\n",
    "                resolution = res_match.group(1)\n",
    "        if line.startswith('REMARK 350'):\n",
    "            # Get the author determined biological assembly\n",
    "            match_assembly = re.search('BIOMOLECULE:[ ]+([0-9]+)', line)\n",
    "            if match_assembly:   \n",
    "                if quit_bool:\n",
    "                    subunit_number = dict_text_2_numbers.get(subunit_number, subunit_number)\n",
    "                    return [pdb_id, bio_assembly, subunit_number, expdata, resolution, chains_dict]\n",
    "                else:\n",
    "                    bio_assembly = int(match_assembly.group(1))\n",
    "            \n",
    "            \n",
    "            match_author = re.search('AUTHOR DETERMINED BIOLOGICAL UNIT: ([a-zA-Z0-9]+)', line)\n",
    "            if match_author:\n",
    "                subunit_number = match_author.group(1)\n",
    "                \n",
    "                quit_bool = True\n",
    "            \n",
    "            # Check which chains are in this biological assembly\n",
    "            match_chains_1 = re.search('APPLY THE FOLLOWING TO CHAINS: ([a-zA-Z0-9, ]+)', line)\n",
    "            if match_chains_1:\n",
    "                chains_assembly = match_chains_1.group(1).strip()\n",
    "            \n",
    "            # Sometimes the chains don't fit in a single line (example: 2ja7)\n",
    "            match_chains_2 = re.search('AND CHAINS: ([a-zA-Z0-9, ]+)', line)\n",
    "            if match_chains_2:\n",
    "                chains_assembly = chains_assembly + ' ' + match_chains_2.group(1).strip()\n",
    "            \n",
    "            # Sometimes a single chain is used to obtain two chains (example: 3qps)\n",
    "            match_biomt = re.search('BIOMT\\d   (\\d)', line)\n",
    "            if match_biomt:\n",
    "                all_chains = chains_assembly.split(', ')\n",
    "                for chain in all_chains:\n",
    "                    chains_dict[chain] = int(match_biomt.group(1))\n",
    "            \n",
    "            \n",
    "    # Structures without reported biological assemblies will be considered monomers\n",
    "    if quit_bool:\n",
    "\n",
    "        subunit_number = dict_text_2_numbers.get(subunit_number, subunit_number)\n",
    "        return [pdb_id, bio_assembly, subunit_number, expdata, resolution, chains_dict]\n",
    "    else:\n",
    "        return [pdb_id, 1, 1, expdata, resolution, chains_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the data\n",
    "file_list = glob.glob(pdb_folder + '*pdb')\n",
    "structure_dict = OrderedDict()\n",
    "\n",
    "for pdb_file in file_list:\n",
    "    new_line = extract_pdb_data(pdb_file, dict_text_2_numbers)\n",
    "\n",
    "    structure_dict[new_line[0]] = new_line[1:6]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the alignment data as a dictionary\n",
    "alignment_dict = OrderedDict()\n",
    "handle_in = open('Data/PDB_matches.txt', 'r')\n",
    "reader = csv.reader(handle_in, delimiter = '\\t')\n",
    "\n",
    "unspecific_dict = OrderedDict()\n",
    "dup_type_dict = OrderedDict()\n",
    "\n",
    "for line in reader:\n",
    "    P1 = line[0]\n",
    "    P2_list = line[14].split(',')\n",
    "    \n",
    "    # Skip the first line\n",
    "    if P1 == 'P1':\n",
    "        continue\n",
    "    \n",
    "    aln_length = int(line[4])\n",
    "    \n",
    "    # Skip matches that have alignment lengths shorter than 50\n",
    "    if aln_length < 50:\n",
    "        continue\n",
    "    \n",
    "    for P2 in P2_list:\n",
    "        pair_list = [P1, P2]\n",
    "        pair_list.sort()\n",
    "        pair = tuple(pair_list)\n",
    "\n",
    "        P1_match_PDB = line[1]\n",
    "        P1_match_chain = line[2]\n",
    "\n",
    "        # Start filling the dictionary\n",
    "        if alignment_dict.get(pair, -1) == -1:\n",
    "\n",
    "            # First level\n",
    "            alignment_dict[pair] = OrderedDict()\n",
    "\n",
    "            # Second level\n",
    "            alignment_dict[pair][P1] = OrderedDict()\n",
    "            alignment_dict[pair][P2] = OrderedDict()\n",
    "\n",
    "            # Third level\n",
    "            alignment_dict[pair][P1][P1_match_PDB] = [P1_match_chain]\n",
    "\n",
    "        # For new PDB structures for paralogs that were already added\n",
    "        elif alignment_dict[pair][P1].get(P1_match_PDB, -1) == -1:\n",
    "            alignment_dict[pair][P1][P1_match_PDB] = [P1_match_chain]\n",
    "\n",
    "        # Append the chain to the list of chains\n",
    "        else:\n",
    "            alignment_dict[pair][P1][P1_match_PDB].append(P1_match_chain)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the alignment dictionary to get the best structures for each protein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle_out = open(output_path + '/paralogs_PDB_structures_complete_over50.txt', 'w')\n",
    "writer = csv.writer(handle_out, delimiter = '\\t')\n",
    "header = ['P1_ID', 'P2_ID', 'Monomer_P1', 'Monomer_P2', 'HM_P1', 'HM_P2', 'HET', 'other_HET_P1', 'other_HET_P2']\n",
    "writer.writerow(header)\n",
    "\n",
    "# Loop through the pairs of paralogs\n",
    "for pair in alignment_dict.keys():\n",
    "    P1 = pair[0]\n",
    "    P2_list = pair[1].split(',')\n",
    "\n",
    "    monomers_P1_list = []\n",
    "    monomers_P2_list = []\n",
    "    HM_P1_list = []\n",
    "    HM_P2_list = []\n",
    "    other_HET_P1_list = []\n",
    "    other_HET_P2_list = []\n",
    "    HET_list = []\n",
    "    \n",
    "    # Work with P1 and the list of structures whose chains match it\n",
    "    for structure, chains in alignment_dict[pair][P1].items():\n",
    "        # Skip the big structures that could not be downloaded\n",
    "        if structure in ['5gjr', '5l4g', '5t0c']:\n",
    "            continue\n",
    "        elif structure == '5len': # A superseeded structure\n",
    "            structure = '6f5e'\n",
    "        elif structure == '3ou5': # A superseeded structure\n",
    "            structure = '6dk3'\n",
    "        \n",
    "        # Skip structures that were solved with NMR\n",
    "        if structure_dict[structure][2] == 'SOLUTION NMR' or structure_dict[structure][2] == 'SOLID-STATE NMR':\n",
    "            continue\n",
    "        elif len(structure_dict[structure][4].keys()) == 0:\n",
    "            matches_in_structure = len(chains)\n",
    "        else:\n",
    "            matches_in_structure = 0\n",
    "            for chain in chains:\n",
    "                # Check the number of chains in the assembly that derive from this chain\n",
    "                chain_matches = structure_dict[structure][4].get(chain, 0)\n",
    "                matches_in_structure = matches_in_structure + chain_matches\n",
    "        \n",
    "        # Check if this is a monomer (the assembly has only one chain AND there is one match)\n",
    "        if structure_dict[structure][1] == 1 and matches_in_structure == 1:\n",
    "            \n",
    "            monomer_P1 = structure + '_' + str(structure_dict[structure][0])\n",
    "            monomers_P1_list.append(monomer_P1)\n",
    "        # Check if this is a HM (the assembly has more than one chain AND this paralog matches more than one chain)\n",
    "        elif structure_dict[structure][1] > 1 and matches_in_structure > 1:\n",
    "            HM_P1 = structure + '_' + str(structure_dict[structure][0])\n",
    "            HM_P1_list.append(HM_P1)\n",
    "        # Check if this is a HET but not of paralogs (other_HET)\n",
    "        elif structure_dict[structure][1] > 1 and matches_in_structure == 1:\n",
    "            other_HET_P1 = structure + '_' + str(structure_dict[structure][0])\n",
    "            other_HET_P1_list.append(other_HET_P1)\n",
    "    \n",
    "    # Work with the isoforms of P2\n",
    "    for P2 in P2_list:\n",
    "        for structure, chains in alignment_dict[pair][P2].items():\n",
    "            # Skip the big structures could not be downloaded\n",
    "            if structure in ['5gjr', '5l4g', '5t0c']:\n",
    "                continue\n",
    "            elif structure == '5len': # A superseeded structure\n",
    "                structure = '6f5e'\n",
    "            elif structure == '3ou5': # A superseeded structure\n",
    "                structure = '6dk3'\n",
    "\n",
    "            # Skip structures that were solved with NMR\n",
    "            if structure_dict[structure][2] == 'SOLUTION NMR' or structure_dict[structure][2] == 'SOLID-STATE NMR':\n",
    "                continue\n",
    "            \n",
    "            elif len(structure_dict[structure][4].keys()) == 0:\n",
    "                matches_in_structure = len(chains)\n",
    "            else:\n",
    "                matches_in_structure = 0\n",
    "                for chain in chains:\n",
    "                    # Check the number of chains in the assembly that derive from this chain\n",
    "                    chain_matches = structure_dict[structure][4].get(chain, 0)\n",
    "                    matches_in_structure = matches_in_structure + chain_matches\n",
    "\n",
    "            # Check if this is a monomer (the assembly has only one chain AND there is only one match)\n",
    "            if structure_dict[structure][1] == 1 and matches_in_structure == 1:\n",
    "                \n",
    "                monomer_P2 = structure + '_' + str(structure_dict[structure][0])\n",
    "                monomers_P2_list.append(monomer_P2)\n",
    "            # Check if this is a HM (the assembly has more than one chain AND this paralog matches more than one chain)\n",
    "            elif structure_dict[structure][1] > 1 and matches_in_structure > 1:\n",
    "                HM_P2 = structure + '_' + str(structure_dict[structure][0])\n",
    "                HM_P2_list.append(HM_P2)\n",
    "            # Check if this is a HET but not of paralogs (other_HET)\n",
    "            elif structure_dict[structure][1] > 1 and matches_in_structure == 1:\n",
    "                other_HET_P2 = structure + '_' + str(structure_dict[structure][0])\n",
    "                other_HET_P2_list.append(other_HET_P2)\n",
    "\n",
    "        # Get the list of HET\n",
    "        # Start with the list of structures that have a match of P1 and P2\n",
    "        P1_matches = alignment_dict[pair][P1].keys()\n",
    "        P2_matches = alignment_dict[pair][P2].keys()\n",
    "\n",
    "        # Loop through each of the structures in P1_matches and check if it also has matches for P2\n",
    "        for candidate in P1_matches:\n",
    "            if candidate in P2_matches:\n",
    "                chains_P1 = alignment_dict[pair][P1][candidate]\n",
    "                chains_P2 = alignment_dict[pair][P2][candidate]\n",
    "                total_chains = structure_dict[candidate][1]\n",
    "                assembly = structure_dict[candidate][0]\n",
    "\n",
    "                chains_P1_match = 0\n",
    "                if len(structure_dict[candidate][4].keys()) == 0:\n",
    "                    chains_P1_match = len(chains_P1)\n",
    "                else:\n",
    "                    for chain in chains_P1:\n",
    "                        P1_chain_matches = structure_dict[candidate][4].get(chain, 0)\n",
    "                        chains_P1_match = chains_P1_match + P1_chain_matches \n",
    "\n",
    "                chains_P2_match = 0\n",
    "                if len(structure_dict[candidate][4].keys()) == 0:\n",
    "                    chains_P2_match = len(chains_P2)\n",
    "                else:\n",
    "                    for chain in chains_P2:\n",
    "                        P2_chain_matches = structure_dict[candidate][4].get(chain, 0)\n",
    "                        chains_P2_match = chains_P2_match + P2_chain_matches             \n",
    "\n",
    "                # Check if:\n",
    "                # There is at least one match for P1 AND \n",
    "                # There is at least one match for P2 AND\n",
    "                # The assembly has at least as many subunits as the sum of matches of P1 and P2\n",
    "                if chains_P1_match >= 1 and chains_P2_match >= 1 and total_chains >= (chains_P1_match + chains_P2_match):\n",
    "                    HET = candidate + '_' + str(assembly)\n",
    "                    HET_list.append(HET)\n",
    "                    # Remove them from the lists of other HET if they are there\n",
    "                    if HET in other_HET_P1_list:\n",
    "                        other_HET_P1_list.remove(HET)\n",
    "                    if HET in other_HET_P2_list:\n",
    "                        other_HET_P2_list.remove(HET)\n",
    "\n",
    "        # Assemble the table\n",
    "        save_bool = False\n",
    "        if len(monomers_P1_list) == 0:\n",
    "            monomers_P1 = 'NA'\n",
    "        else:\n",
    "            monomers_P1 = ','.join(monomers_P1_list)\n",
    "            save_bool = True\n",
    "\n",
    "        if len(monomers_P2_list) == 0:\n",
    "            monomers_P2 = 'NA'\n",
    "        else:    \n",
    "            monomers_P2 = ','.join(monomers_P2_list)\n",
    "            save_bool = True\n",
    "\n",
    "        if len(HM_P1_list) == 0:\n",
    "            HM_P1 = 'NA'\n",
    "        else:\n",
    "            HM_P1 = ','.join(HM_P1_list)\n",
    "            save_bool = True\n",
    "\n",
    "        if len(HM_P2_list) == 0:\n",
    "            HM_P2 = 'NA'\n",
    "        else:\n",
    "            HM_P2 = ','.join(HM_P2_list)\n",
    "            save_bool = True\n",
    "\n",
    "        if len(HET_list) == 0:\n",
    "            HET = 'NA'\n",
    "        else:\n",
    "            HET = ','.join(HET_list)\n",
    "            save_bool = True\n",
    "\n",
    "        if len(other_HET_P1_list) == 0:\n",
    "            other_HET_P1 = 'NA'\n",
    "        else:\n",
    "            other_HET_P1 = ','.join(other_HET_P1_list)\n",
    "            save_bool = True\n",
    "\n",
    "        if len(other_HET_P2_list) == 0:\n",
    "            other_HET_P2 = 'NA'\n",
    "        else:\n",
    "            other_HET_P2 = ','.join(other_HET_P2_list)\n",
    "            save_bool = True\n",
    "\n",
    "        # Put everything together and write the new row\n",
    "        if save_bool == True:\n",
    "            # new_row = [P1, P2, dup_type, monomers_P1, monomers_P2, HM_P1, HM_P2, HET, other_HET_P1, other_HET_P2, P1_unspecific, P2_unspecific]\n",
    "            new_row = [P1, P2, monomers_P1, monomers_P2, HM_P1, HM_P2, HET, other_HET_P1, other_HET_P2]\n",
    "            writer.writerow(new_row)\n",
    "\n",
    "handle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look for the strict homomers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the final data table\n",
    "handle = open(output_path + '/paralogs_PDB_structures_complete_over50.txt', 'r')\n",
    "table_reader = csv.reader(handle, delimiter = '\\t')\n",
    "\n",
    "# Skip headers\n",
    "header = table_reader.next()\n",
    "\n",
    "# Prepare the file to write\n",
    "handle_writer = open(output_path + '/paralogs_PDB_structures_with_strict_over50.txt', 'w')\n",
    "writer = csv.writer(handle_writer, delimiter = '\\t')\n",
    "\n",
    "header = ['P1_ID', 'P2_ID', 'Monomer_P1', 'Monomer_P2', 'HM_P1', 'HM_P2', 'HET', 'other_HET_P1', 'other_HET_P2', 'Strict_HM_P1', 'Strict_HM_P2']   \n",
    "writer.writerow(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in table_reader:\n",
    "    \n",
    "    paralog_1 = line[0]\n",
    "    paralog_2 = line[1]\n",
    "    HM_1 = line[4]\n",
    "    HM_2 = line[5]\n",
    "    HET = line[6]\n",
    "    strict_HM_1 = []\n",
    "    strict_HM_2 = []\n",
    "    \n",
    "    HM_1 = HM_1.split(',')\n",
    "    HM_2 = HM_2.split(',')\n",
    "\n",
    "    if HM_1[0] == 'NA':\n",
    "        line.append('NA')\n",
    "    else:\n",
    "        # Look at each of the structures in HM_1 and HM_2 and their chains based on the\n",
    "        # alignment and structure dictionaries.\n",
    "        for structure in HM_1:\n",
    "            # Check which chains in that structure correspond to paralog 1\n",
    "            chains = alignment_dict[(paralog_1, paralog_2)][paralog_1][structure[0:4]]\n",
    "            # Get the total number of chains that come from those chains\n",
    "            total = 0\n",
    "\n",
    "            for chain in chains:\n",
    "                # Get the total number of chains that come from those chains\n",
    "                chain_appears = structure_dict[structure[0:4]][4].get(chain,0)\n",
    "\n",
    "                # Count the total number of chains\n",
    "                total = total + chain_appears\n",
    "\n",
    "            # Check if it is a strict HM. This would be the case if all the chains that form the structure were matches\n",
    "            if total == structure_dict[structure[0:4]][1]:\n",
    "                strict_HM_1.append(structure)\n",
    "        \n",
    "        # Now, add the data on strict homomers to the line and write to a file\n",
    "        # If there are strict homomers we write them to the column. Otherwise, write NA.\n",
    "        if len(strict_HM_1) > 0:\n",
    "            strict_HM_1_final = ','.join(strict_HM_1)\n",
    "            line.append(strict_HM_1_final)\n",
    "        else:\n",
    "            line.append('NA')\n",
    "\n",
    "    # Repeat for HM_2\n",
    "    if HM_2[0] == 'NA':\n",
    "        line.append('NA')\n",
    "    else:\n",
    "        for structure in HM_2:\n",
    "            # Check which chains in that structure correspond to paralog 2\n",
    "            chains = alignment_dict[(paralog_1, paralog_2)][paralog_2][structure[0:4]]\n",
    "            # Get the total number of chains that come from those chains\n",
    "            total = 0\n",
    "\n",
    "            for chain in chains:\n",
    "                # Get the total number of times this chain appears in the biological assembly\n",
    "                # Some might not appear because they could be present in the file but in a different assembly\n",
    "                chain_appears = structure_dict[structure[0:4]][4].get(chain, 0)\n",
    "\n",
    "                # Count the total number of chains\n",
    "                total = total + chain_appears \n",
    "\n",
    "            # Check if it is a strict HM. This would be the case if all the chains that form the structure were matches\n",
    "            if total == structure_dict[structure[0:4]][1]:\n",
    "                strict_HM_2.append(structure)\n",
    "\n",
    "        if len(strict_HM_2) > 0:\n",
    "            strict_HM_2_final = ','.join(strict_HM_2)\n",
    "            line.append(strict_HM_2_final)\n",
    "        else:\n",
    "            line.append('NA')\n",
    "    \n",
    "    writer.writerow(line)\n",
    "\n",
    "handle_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the complexes with the best resolution for interface analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle = open(output_path + '/paralogs_PDB_structures_with_strict_over50.txt', 'r')\n",
    "reader = csv.reader(handle, delimiter = '\\t')\n",
    "\n",
    "handle_writer = open(output_path + '/paralogs_PDB_structures_best_structures_over50.txt', 'w')\n",
    "writer = csv.writer(handle_writer, delimiter = '\\t')\n",
    "\n",
    "header = ['P1_ID', 'P2_ID', 'HM_P1', 'HM_P2', 'HET','Strict_HM_P1', 'Strict_HM_P2']   \n",
    "writer.writerow(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip the first line\n",
    "header = reader.next()\n",
    "\n",
    "for line in reader:\n",
    "    P1_ID = line[0]\n",
    "    P2_ID = line[1]\n",
    "    dup_type = line[2]\n",
    "    \n",
    "    HM_P1 = line[4]\n",
    "    best_HM_P1 = ['NA', 1000]\n",
    "    \n",
    "    HM_P2 = line[5]\n",
    "    best_HM_P2 = ['NA', 1000]\n",
    "    \n",
    "    HET = line[6]\n",
    "    best_HET = ['NA', 1000]\n",
    "    \n",
    "    strict_HM_P1 = line[9]\n",
    "    best_strict_HM_P1 = ['NA', 1000]\n",
    "    \n",
    "    strict_HM_P2 = line[10]\n",
    "    best_strict_HM_P2 = ['NA', 1000]\n",
    "    \n",
    "    bool_save = False\n",
    "    \n",
    "    # Look at the list of structures in each column, and select the crystal with the best resolution\n",
    "    if HM_P1 != 'NA':\n",
    "        for structure in HM_P1.split(','):\n",
    "            # Get the resolution of such structure if it is a crystal\n",
    "            structure_info = structure_dict[structure[0:4]]\n",
    "            technique = structure_info[2]\n",
    "            resolution = float(structure_info[3])\n",
    "            if technique == 'X-RAY DIFFRACTION' and resolution < best_HM_P1[1]:\n",
    "                best_HM_P1 = [structure, resolution]\n",
    "                bool_save = True\n",
    "    \n",
    "    \n",
    "    if HM_P2 != 'NA':\n",
    "        for structure in HM_P2.split(','):\n",
    "            # Get the resolution of such structure if it is a crystal\n",
    "            structure_info = structure_dict[structure[0:4]]\n",
    "            technique = structure_info[2]\n",
    "            resolution = float(structure_info[3])\n",
    "            if technique == 'X-RAY DIFFRACTION' and resolution < best_HM_P2[1]:\n",
    "                best_HM_P2 = [structure, resolution]\n",
    "                bool_save = True\n",
    "                \n",
    "    if HET != 'NA':\n",
    "        for structure in HET.split(','):\n",
    "            # Get the resolution of such structure if it is a crystal\n",
    "            structure_info = structure_dict[structure[0:4]]\n",
    "            technique = structure_info[2]\n",
    "            resolution = float(structure_info[3])\n",
    "            if technique == 'X-RAY DIFFRACTION' and resolution < best_HET[1]:\n",
    "                best_HET = [structure, resolution]\n",
    "                bool_save = True\n",
    "            \n",
    "    if strict_HM_P1 != 'NA':\n",
    "        for structure in strict_HM_P1.split(','):\n",
    "            # Get the resolution of such structure if it is a crystal\n",
    "            structure_info = structure_dict[structure[0:4]]\n",
    "            technique = structure_info[2]\n",
    "            resolution = float(structure_info[3])\n",
    "            if technique == 'X-RAY DIFFRACTION' and resolution < best_strict_HM_P1[1]:\n",
    "                best_strict_HM_P1 = [structure, resolution]\n",
    "                bool_save = True\n",
    "            \n",
    "    if strict_HM_P2 != 'NA':\n",
    "        for structure in strict_HM_P2.split(','):\n",
    "            # Get the resolution of such structure if it is a crystal\n",
    "            structure_info = structure_dict[structure[0:4]]\n",
    "            technique = structure_info[2]\n",
    "            resolution = float(structure_info[3])\n",
    "            if technique == 'X-RAY DIFFRACTION' and resolution < best_strict_HM_P2[1]:\n",
    "                best_strict_HM_P2 = [structure, resolution]\n",
    "                bool_save = True\n",
    "                \n",
    "    # Now that we have all of them, write the info to the table\n",
    "    if bool_save:\n",
    "        new_row = [P1_ID, P2_ID, best_HM_P1[0], best_HM_P2[0], best_HET[0], best_strict_HM_P1[0], best_strict_HM_P2[0]]\n",
    "        writer.writerow(new_row)\n",
    "        \n",
    "handle_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
